{"article-title": "Associating Facial Expressions and Upper-Body Gestures with Learning Tasks for Enhancing Intelligent Tutoring Systems", "author": [{"author-name": "Ardhendu Behera"}, {"author-name": "Peter Matthew"}, {"author-name": "Alexander Keidel"}, {"author-name": "Peter Vangorp"}, {"author-name": "Hui Fang"}, {"author-name": "Susan Canning"}], "journal-title": "International Journal of Artificial Intelligence in Education", "journal-volume": "volume30", "pageStart": "236", "pageEnd": "270", "publication-year": "2020", "keywords": ["Adaptive and intelligent multimedia and hypermedia systems", "Intelligent Tutoring Systems (ITSs)", "Computer-supported collaborative learning", "Neural models applied to AIED systems"], "citation": "Behera, A., Matthew, P., Keidel, A. et al. Associating Facial Expressions and Upper-Body Gestures with Learning Tasks for Enhancing Intelligent Tutoring Systems.\n                    Int J Artif Intell Educ 30, 236\u2013270 (2020). https://doi.org/10.1007/s40593-020-00195-2", "abstract": "Learning involves a substantial amount of cognitive, social and emotional states. Therefore, recognizing and understanding these states in the context of learning is key in designing informed interventions and addressing the needs of the individual student to provide personalized education. In this paper, we explore the automatic detection of learner\u2019s nonverbal behaviors involving hand-over-face gestures, head and eye movements and emotions via facial expressions during learning. The proposed computer vision-based behavior monitoring method uses a low-cost webcam and can easily be integrated with modern tutoring technologies. We investigate these behaviors in-depth over time in a classroom session of 40 minutes involving reading and problem-solving exercises. The exercises in the sessions are divided into three categories: an easy, medium and difficult topic within the context of undergraduate computer science. We found that there is a significant increase in head and eye movements as time progresses, as well as with the increase of difficulty level. We demonstrated that there is a considerable occurrence of hand-over-face gestures (on average 21.35%) during the 40 minutes session and is unexplored in the education domain. We propose a novel deep learning approach for automatic detection of hand-over-face gestures in images with a classification accuracy of 86.87%. There is a prominent increase in hand-over-face gestures when the difficulty level of the given exercise increases. The hand-over-face gestures occur more frequently during problem-solving (easy 23.79%, medium 19.84% and difficult 30.46%) exercises in comparison to reading (easy 16.20%, medium 20.06% and difficult 20.18%)."}