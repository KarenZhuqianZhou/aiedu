"article.title","journal.title","journal.volume","pageStart","pageEnd","publication.year","citation","abstract"
"Teaching the Teacher: Tutoring SimStudent Leads to More Effective Cognitive Tutor Authoring","International Journal of Artificial Intelligence in Education","volume25","1","34","2015","Matsuda, N., Cohen, W.W. & Koedinger, K.R. Teaching the Teacher: Tutoring SimStudent Leads to More Effective Cognitive Tutor Authoring. Int J Artif Intell Educ 25, 1–34 (2015). https://doi.org/10.1007/s40593-014-0020-1","SimStudent is a machine-learning agent initially developed to help novice authors to create cognitive tutors without heavy programming. Integrated into an existing suite of software tools called Cognitive Tutor Authoring Tools (CTAT), SimStudent helps authors to create an expert model for a cognitive tutor by tutoring SimStudent on how to solve problems. There are two different ways to author an expert model with SimStudent. In the context of Authoring by Tutoring, the author interactively tutors SimStudent by posing problems to SimStudent, providing feedback on the steps performed by SimStudent, and also demonstrating steps as a response to SimStudent’s hint requests when SimStudent cannot perform steps correctly. In the context of Authoring by Demonstration, the author demonstrates solution steps, and SimStudent attempts to induce underlying domain principles by generalizing those worked-out examples. We conducted evaluation studies to investigate which authoring strategy better facilitates authoring and found two key results. First, the expert model generated with Authoring by Tutoring is better and has higher accuracy while maintaining the same level of completeness than the one generated with Authoring by Demonstration. The reason for this better accuracy is that the expert model generated by tutoring benefits from negative feedback provided for SimStudent’s incorrect production applications. Second, authoring by Tutoring requires less time than Authoring by Demonstration. This enhanced authoring efficiency is partially because (a) when Authoring by Demonstration, the author needs to test the quality of the expert model, whereas the formative assessment of the expert model is done naturally by observing SimStudent’s performance when Authoring by Tutoring, and (b) the number of steps that need to be demonstrated during tutoring decreases as learning progresses."
"Narrative Balance Management in an Intelligent Biosafety Training Application for Improving User Performance","International Journal of Artificial Intelligence in Education","volume25","35","59","2015","Alvarez, N., Sanchez-Ruiz, A., Cavazza, M. et al. Narrative Balance Management in an Intelligent Biosafety Training Application for Improving User Performance. Int J Artif Intell Educ 25, 35–59 (2015). https://doi.org/10.1007/s40593-014-0022-z","The use of three-dimensional virtual environments in training applications supports the simulation of complex scenarios and realistic object behaviour. While these environments have the potential to provide an advanced training experience to students, it is difficult to design and manage a training session in real time due to the number of parameters to pay attention to: timing of events, difficulty, user’s actions and their consequences or eventualities are some examples. For that purpose, we have extended our virtual Bio-safety Laboratory application used for training biohazard procedures with a Narrative Manager. The Narrative Manager controls the simulation deciding which events will take place in the simulation, and when, by controlling the narrative balance of the session. Our hypothesis is that the Narrative Manager allows us to increase the number of tasks for the user to solve and, due to balancing difficulty and intensity, it keeps the user interested in training. When evaluating our system we observed that the Narrative Manager effectively introduces more tasks for the user to solve, and despite that, is accepted by the users as more interesting and not harder than an identical system without a Narrative Manager. Also, a knowledge test demonstrated better results in users’ interest and learning output in the narrative condition."
"The Eras and Trends of Automatic Short Answer Grading","International Journal of Artificial Intelligence in Education","volume25","60","117","2015","Burrows, S., Gurevych, I. & Stein, B. The Eras and Trends of Automatic Short Answer Grading. Int J Artif Intell Educ 25, 60–117 (2015). https://doi.org/10.1007/s40593-014-0026-8","Automatic short answer grading (ASAG) is the task of assessing short natural language responses to objective questions using computational methods. The active research in this field has increased enormously of late with over 80 papers fitting a definition of ASAG. However, the past efforts have generally been ad-hoc and non-comparable until recently, hence the need for a unified view of the whole field. The goal of this paper is to address this aim with a comprehensive review of ASAG research and systems according to history and components. Our historical analysis identifies 35 ASAG systems within 5 temporal themes that mark advancement in methodology or evaluation. In contrast, our component analysis reviews 6 common dimensions from preprocessing to effectiveness. A key conclusion is that an era of evaluation is the newest trend in ASAG research, which is paving the way for the consolidation of the field."
"Socio-Cultural Imbalances in AIED Research: Investigations, Implications and Opportunities","International Journal of Artificial Intelligence in Education","volume25","204","228","2015","Blanchard, E.G. Socio-Cultural Imbalances in AIED Research: Investigations, Implications and Opportunities. Int J Artif Intell Educ 25, 204–228 (2015). https://doi.org/10.1007/s40593-014-0027-7","This paper investigates international representations in the Artificial Intelligence in Education (AIED) research field. Its methodological and theoretical groundings are inspired by Arnett (2008) and Henrich et al. (2010a) who addressed the same issue in psychology, and respectively a) discovered massive imbalances in representation in top-tier psychology journals, and b) clarified risks of this situation. Data on research production collected on 2 top-tiers AIED conferences indicate that relatively similar imbalances exist in AIED. Potential threats and challenges induced by that situation are discussed as well as additionally identified phenomena related to the culture of the AIED community."
"Intelligent Tutoring Systems by and for the Developing World: A Review of Trends and Approaches for Educational Technology in a Global Context","International Journal of Artificial Intelligence in Education","volume25","177","203","2015","Nye, B.D. Intelligent Tutoring Systems by and for the Developing World: A Review of Trends and Approaches for Educational Technology in a Global Context. Int J Artif Intell Educ 25, 177–203 (2015). https://doi.org/10.1007/s40593-014-0028-6","As information and communication technology access expands in the developing world, learning technologies have the opportunity to play a growing role to enhance and supplement strained educational systems. Intelligent tutoring systems (ITS) offer strong learning gains, but are a class of technology traditionally designed for most-developed countries. Recently, closer consideration has been made to ITS targeting the developing world and to culturally-adapted ITS. This paper presents findings from a systematic literature review that focused on barriers to ITS adoption in the developing world. While ITS were the primary focus of the review, the implications likely apply to a broader range of educational technology as well. The geographical and economic landscape of tutoring publications is mapped out, to determine where tutoring systems research occurs. Next, the paper discusses challenges and promising solutions for barriers to ITS within both formal and informal settings. These barriers include student basic computing skills, hardware sharing, mobile-dominant computing, data costs, electrical reliability, internet infrastructure, language, and culture. Differences and similarities between externally-developed and locally-developed tutoring system research for the developing world are then considered. Finally, this paper concludes with some potential future directions and opportunities for research on tutoring systems and other educational technologies on the global stage."
"Designing a Knowledge Representation Approach for the Generation of Pedagogical Interventions by MTTs","International Journal of Artificial Intelligence in Education","volume25","118","156","2015","Paquette, L., Lebeau, J., Beaulieu, G. et al. Designing a Knowledge Representation Approach for the Generation of Pedagogical Interventions by MTTs. Int J Artif Intell Educ 25, 118–156 (2015). https://doi.org/10.1007/s40593-014-0030-z","Model-tracing tutors (MTTs) have proven effective for the tutoring of well-defined tasks, but the pedagogical interventions they produce are limited and usually require the inclusion of pedagogical content, such as text message templates, in the model of the task. The capability to generate pedagogical content would be beneficial to MTT frameworks, as it would lessen the task-specific efforts and could lead to the capability of providing more sophisticated pedagogical interventions. In this paper, we show how Astus, as an MTT framework, strive to attain a higher level of automation when generating pedagogical interventions compared to other MTT frameworks such as TDK and CTAT’s MTTs. This is achieved by designing a knowledge representation approach in which each type of knowledge unit has a clearly defined semantic on which the MTT’s pedagogical module can rely on. We explain how this knowledge representation approach is implemented as a knowledge-based system in ASTUS and show how it allows the development of MTTs that can automatically generate the pedagogical content required to provide next-step hints and negative feedback on errors. Multiple small-scale experiments were conducted with computer science undergraduate students in order to obtain a preliminary assessment of the effectiveness of Astus’s pedagogical interventions."
"Learning to Overcome Cultural Conflict through Engaging with Intelligent Agents in Synthetic Cultures","International Journal of Artificial Intelligence in Education","volume25","291","317","2015","Hall, L., Tazzyman, S., Hume, C. et al. Learning to Overcome Cultural Conflict through Engaging with Intelligent Agents in Synthetic Cultures. Int J Artif Intell Educ 25, 291–317 (2015). https://doi.org/10.1007/s40593-014-0031-y","Providing opportunities for children to engage with intercultural learning has frequently focused on exposure to the ritual, celebrations and festivals of cultures, with the view that such experiences will result in greater acceptance of cultural differences. Intercultural conflict is often avoided, bringing as it does particular pedagogical, ethical and political dilemmas of which cultures we place in conflict in the multicultural classroom. In this paper we discuss an alternative approach, providing children with an interactive learning experience with synthetic cultures and characters. The agent architecture developed to enable intelligent agents to exhibit culturally appropriate affect and behaviours is outlined. MIXER, an experiential learning application developed for 9–11 year old children on intercultural conflict is described, highlighting the learning goals and approaches. A school-based evaluation of MIXER with 144 UK children is presented. Children demonstrated high levels of comprehension, engagement and enjoyment of MIXER, with MIXER contributing to near and far transfer, supporting children’s cognitive, emotional and behavioural learning and stimulating discussion and debate about how to resolve conflict."
"Intelligent Augmented Reality Training for Motherboard Assembly","International Journal of Artificial Intelligence in Education","volume25","157","172","2015","Westerfield, G., Mitrovic, A. & Billinghurst, M. Intelligent Augmented Reality Training for Motherboard Assembly. Int J Artif Intell Educ 25, 157–172 (2015). https://doi.org/10.1007/s40593-014-0032-x","We investigate the combination of Augmented Reality (AR) with Intelligent Tutoring Systems (ITS) to assist with training for manual assembly tasks. Our approach combines AR graphics with adaptive guidance from the ITS to provide a more effective learning experience. We have developed a modular software framework for intelligent AR training systems, and a prototype based on this framework that teaches novice users how to assemble a computer motherboard. An evaluation found that our intelligent AR system improved test scores by 25 % and that task performance was 30 % faster compared to the same AR training system without intelligent support. We conclude that using an intelligent AR tutor can significantly improve learning compared to more traditional AR training."
"Dynamic Cultural Contextualisation of Educational Content in Intelligent Learning Environments using ICON","International Journal of Artificial Intelligence in Education","volume25","249","270","2015","Mohammed, P., Mohan, P. Dynamic Cultural Contextualisation of Educational Content in Intelligent Learning Environments using ICON. Int J Artif Intell Educ 25, 249–270 (2015). https://doi.org/10.1007/s40593-014-0033-9","Cultural awareness, when applied to Intelligent Learning Environments (ILEs), contours the overall appearance, behaviour, and content used in these systems through the use of culturally-relevant student data and information. In most cases, these adaptations are system-initiated with little to no consideration given to student-initiated control over the extent of cultural-awareness being used. This paper examines some of the issues relevant to these challenges through the development of the ICON (Instructional Cultural cONtextualisation) system. The paper explores computational approaches for modelling the diversity of students within subcultures, and the necessary semantic formalisms for representing and reasoning about cultural backgrounds at an appropriate level of granularity for ILEs. The paper investigates how student-initiated control of dynamic cultural adaptation of educational content can be achieved in ILEs, and examines the effects of cultural variations of language formality and contextualisation on student preferences for different types of educational content. Evaluations revealed preliminary insight into quantifiable thresholds at which student perception for specific types of culturally-contextualised content vary. The findings further support the notion put forth in the paper that student-initiated control of cultural contextualisation should be featured in ILEs aiming to cater for diverse groups of students."
"Towards Understanding How to Assess Help-Seeking Behavior Across Cultures","International Journal of Artificial Intelligence in Education","volume25","229","248","2015","Ogan, A., Walker, E., Baker, R. et al. Towards Understanding How to Assess Help-Seeking Behavior Across Cultures. Int J Artif Intell Educ 25, 229–248 (2015). https://doi.org/10.1007/s40593-014-0034-8","In recent years, there has been increasing interest in automatically assessing help seeking, the process of referring to resources outside of oneself to accomplish a task or solve a problem. Research in the United States has shown that specific help-seeking behaviors led to better learning within intelligent tutoring systems. However, intelligent tutors are used differently by students in different countries, raising the question of whether the same help-seeking behaviors are effective and desirable in different cultural settings. To investigate this question, models connecting help-seeking behaviors with learning were generated from datasets from students in three countries – Costa Rica, the Philippines, and the United States, as well as a combined dataset from all three sites. Each model was tested on data from the other countries. This study found that models of effective help seeking transfer to some degree between the United States and Philippines, but not between those countries and Costa Rica. Differences may be explained by variations in classroom practices between the sites; for example, greater collaboration observed in the Costa Rican site indicates that much help seeking occurred outside of the technology. Findings indicate that greater care should be taken when assuming that the models underlying AIED systems generalize across cultures and contexts."
"A Virtual Space for Children to Meet and Practice Chinese","International Journal of Artificial Intelligence in Education","volume25","271","290","2015","Si, M. A Virtual Space for Children to Meet and Practice Chinese. Int J Artif Intell Educ 25, 271–290 (2015). https://doi.org/10.1007/s40593-014-0035-7","Second language acquisition after the students have learned their first language is a unique process. One major difference between learning a foreign language and one’s mother tongue is that second language learning is often facilitated with digital media, and in particular, through interacting with computers. This project is aimed at leveraging computer game technologies and Microsoft Kinect camera to create virtual learning environments suitable for children to practice their language and culture skills. We present a unique virtual environment that contextualizes the practice and engages the learners with narratives, encourages group work and leverages the power of embodied cognition in language learning. Our system has been deployed in an afterschool program for children from 6 to 8 years old. We report our evaluation results and reflections on the deployment process, followed by discussion and future work."
"Implementation and use of Simulated Students for Test and Validation of new Adaptive Educational Systems: a Practical Insight","International Journal of Artificial Intelligence in Education","volume25","319","345","2015","Dorça, F. Implementation and use of Simulated Students for Test and Validation of new Adaptive Educational Systems: a Practical Insight. Int J Artif Intell Educ 25, 319–345 (2015). https://doi.org/10.1007/s40593-015-0037-0","Studies attest that learning is facilitated if teaching strategies are in accordance with students learning styles, making learning process more effective and considerably improving students performances. In this context, one major research point – and a challenge – is to efficiently discover students’ learning styles. But, the test and validation of new approaches in this field requires substantial amounts of financial, human resources (tutors and students) and time. In this way, the use of simulated students for test and validation of new approaches in this field is very important. Therefore, this work depicts the implementation and use of simulation for empirical evaluation of three different strategies for automatic learning styles modelling. It was necessary to compare the efficiency of the strategies, in order to choose the best one. Therefore, it was needed a practical mechanism to evaluate and compare them, preferably without the engagement of human resources. Then, the main goal of using simulation in this work is to compare strategies’ efficiency and to discover the most promising one. The research was empirical, and has led to considerable enhancements on an intelligent component for automatic modelling of learning and teaching styles, which has been tested, adjusted and improved in a reasonable time and with low cost. The best strategy was clearly found, as depicted by experiments and results presented in this paper."
"A Measurement Model of Microgenetic Transfer for Improving Instructional Outcomes","International Journal of Artificial Intelligence in Education","volume25","346","379","2015","Pavlik, P.I., Yudelson, M. & Koedinger, K.R. A Measurement Model of Microgenetic Transfer for Improving Instructional Outcomes. Int J Artif Intell Educ 25, 346–379 (2015). https://doi.org/10.1007/s40593-015-0039-y","Efforts to improve instructional task design often make reference to the mental structures, such as “schemas” (e.g., Gick & Holyoak, 1983) or “identical elements” (Thorndike & Woodworth, 1901), that are common to both the instructional and target tasks. This component based (e.g., Singley & Anderson, 1989) approach has been employed in psychometrics (Tatsuoka, 1983), cognitive science (Koedinger & MacLaren, 2002), and most recently in educational data mining (Cen, Koedinger, & Junker, 2006). A typical assumption of these theory based models is that an itemization of “knowledge components” shared between tasks is sufficient to predict transfer between these tasks. In this paper we step back from these more cognitive theory based models of transfer and suggest a psychometric measurement model that removes most cognitive assumptions, thus allowing us to understand the data without the bias of a theory of transfer or domain knowledge. The goal of this work is to help provide a methodology that allows researchers to analyse complex data without the theoretical assumptions clearly part of other methods. Our experimentally controlled examples illustrate the non-intuitive nature of some transfer situations which motivates the necessity of the unbiased analysis that our model provides. We explain how to use this Contextual Performance Factors Analysis (CPFA) model to measure learning progress of related skills at a fine granularity. This CPFA analysis then allows us to answer questions regarding the best order of practice for related skills and the appropriate amount of repetition depending on whether students are succeeding or failing with each individual practice problem. We conclude by describing how the model allows us to test theories, in which we discuss how well two different cognitive theories agree with the qualitative results of the model."
"The Birth of IJAIED","International Journal of Artificial Intelligence in Education","volume26","4","12","2016","Self, J. The Birth of IJAIED. Int J Artif Intell Educ 26, 4–12 (2016). https://doi.org/10.1007/s40593-015-0040-5","This document tries to describe the events of the early days of AIED research that led to the AIED Conferences and Society and, in particular, the International Journal of Artificial Intelligence in Education."
"Computer-based Assessment of Collaborative Problem Solving: Exploring the Feasibility of Human-to-Agent Approach","International Journal of Artificial Intelligence in Education","volume25","380","406","2015","Rosen, Y. Computer-based Assessment of Collaborative Problem Solving: Exploring the Feasibility of Human-to-Agent Approach. Int J Artif Intell Educ 25, 380–406 (2015). https://doi.org/10.1007/s40593-015-0042-3","How can activities in which collaborative skills of an individual are measured be standardized? In order to understand how students perform on collaborative problem solving (CPS) computer-based assessment, it is necessary to examine empirically the multi-faceted performance that may be distributed across collaboration methods. Theaim of this study was to explore possible differences in student performance in humanto-agent (H-A), compared to human-to-human (H-H) CPS assessment tasks. One hundred seventy nine 14 years-old students from the United States, Singapore and Israel participated in the study. Students in both H-H and H-A modes were able to collaborate and communicate by using identical methods and resources. However, while in the H-A mode, students collaborated with a simulated computer-driven partner, and in the H-H mode students collaborated with another student to solve a problem. Overall, the findings showed that CPS with a computer agent involved significantly higher levels of shared understanding, progress monitoring, and feedback. However, no significant difference was found in a student’s ability to solve the problem or in student motivation with a computer agent or a human partner. One major implication of CPS score difference in collaboration measures between the two modes is that in H-A mode one can program a wider range of interaction possibilities than would be available with a human partner. Thus, H-A approach offers more opportunities for students to demonstrate their CPS skills. This study is among the first of its kind to investigate systematically the effect of collaborative problem solving in standardized assessment settings."
"Spendency: Students’ Propensity to Use System Currency","International Journal of Artificial Intelligence in Education","volume25","407","427","2015","Snow, E.L., Allen, L.K., Jackson, G.T. et al. Spendency: Students’ Propensity to Use System Currency. Int J Artif Intell Educ 25, 407–427 (2015). https://doi.org/10.1007/s40593-015-0044-1","Using students’ process data from the game-based Intelligent Tutoring System (ITS) iSTART-ME, the current study examines students’ propensity to use system currency to unlock game-based features, (i.e., referred to here as spendency). This study examines how spendency relates to students’ interaction preferences, in-system performance, and learning outcomes (i.e., self-explanation quality, comprehension). A group of 40 high school students interacted with iSTART-ME as part of an 11-session experiment (pretest, eight training sessions, posttest, and a delayed retention test). Students’ spendency was negatively related to the frequency of their use of personalizable features. In addition, students’ spendency was negatively related to their in-system achievements, daily learning outcomes, and performance on a transfer comprehension task, even after factoring out prior ability. The findings from this study indicate that increases in students’ spendency are systematically related to their selection choices and may have a negative effect on in-system performance, immediate learning outcomes, and skill transfer outcomes. The results have particular relevance to game-based systems that incorporate currency to unlock features within games as well as to the differential tradeoffs of game features on motivation and learning."
"Authoring Effective Embedded Tutors: An Overview of the Extensible Problem Specific Tutor (xPST) System","International Journal of Artificial Intelligence in Education","volume25","428","454","2015","Gilbert, S.B., Blessing, S.B. & Guo, E. Authoring Effective Embedded Tutors: An Overview of the Extensible Problem Specific Tutor (xPST) System. Int J Artif Intell Educ 25, 428–454 (2015). https://doi.org/10.1007/s40593-015-0045-0","The Extensible Problem Specific Tutor (xPST) allows authors who are not cognitive scientists and not programmers to quickly create an intelligent tutoring system that provides instruction akin to a model-tracing tutor. Furthermore, this instruction is overlaid on existing software, so that the learner’s interface does not have to be made from scratch. The xPST architecture allows for extending its capabilities by the addition of plug-ins that communicate with additional third-party software. After reviewing this general architecture, we describe three major implementations that we have created using the xPST system, each using different third-party software as the learner’s interface. We have conducted three evaluations of authors using xPST to create tutoring content, and these are considered in turn. These evaluations show that xPST authors can quickly learn the system, and can efficiently produce successful embedded instruction."
"A Multi-Temporal Context-aware System for Competences Management","International Journal of Artificial Intelligence in Education","volume25","455","492","2015","Rosa, J.H., Barbosa, J.L.V., Kich, M. et al. A Multi-Temporal Context-aware System for Competences Management. Int J Artif Intell Educ 25, 455–492 (2015). https://doi.org/10.1007/s40593-015-0047-y","The evolution of computing technology and wireless networks has contributed to the miniaturization of mobile devices and their increase in power, providing services anywhere and anytime. In this scenario, applications have considered the user’s contexts to make decisions (Context Awareness). Context-aware applications have enabled new opportunities in different areas, for example, education, games and entertainment, commerce, and competence management. In this article, we present MultCComp, a multi-temporal context-aware system for competences management. The main system contribution is to take advantage of the workers’ present and past contexts to help them to develop their competences. We define as multi-temporal context awareness the joint use of workers’ present and past contexts to assist them in the development of their competences. We developed a prototype and conducted two experiments with it in an evaluation environment. The first experiment aimed to demonstrate the system functionalities. It consisted of two evaluation scenarios that were followed by two users. The second experiment focused on evaluating the acceptance of the system. It comprised a scenario that was followed by 21 users, who filled out a questionnaire at the end of the test."
"Student Modeling Based on Problem Solving Times","International Journal of Artificial Intelligence in Education","volume25","493","519","2015","Pelánek, R., Jarušek, P. Student Modeling Based on Problem Solving Times. Int J Artif Intell Educ 25, 493–519 (2015). https://doi.org/10.1007/s40593-015-0048-x","Student modeling in intelligent tutoring systems is mostly concerned with modeling correctness of students’ answers. As interactive problem solving activities become increasingly common in educational systems, it is useful to focus also on timing information associated with problem solving. We argue that the focus on timing is natural for certain types of educational problems and we describe a simple model of problem solving times which assumes a linear relationship between a latent problem solving skill and a logarithm of a time to solve a problem. The model is closely related to models from two different areas: the item response theory and collaborative filtering. We describe two parameter estimation techniques for the model and several extensions – models with multidimensional skill, learning, or variability of performance. We describe an application of the proposed models in a widely used computerized practice system. Using both simulated data and real data from the system we evaluate the model, analyse its parameter values, and discuss the insight into problem difficulty which the model brings."
"Implementing CBM: SQL-Tutor After Fifteen Years","International Journal of Artificial Intelligence in Education","volume26","150","159","2016","Mitrovic, A., Ohlsson, S. Implementing CBM: SQL-Tutor After Fifteen Years. Int J Artif Intell Educ 26, 150–159 (2016). https://doi.org/10.1007/s40593-015-0049-9","SQL-Tutor is the first constraint-based tutor. The initial conference papers about the system were published in 1998 (Mitrovic 1998a, 1998b, 1998c), with an IJAIED paper published in 1999 (Mitrovic and Ohlsson, International Journal Artificial Intelligence in Education, 10(3–4), 238–256, 1999). We published another IJAIED paper in 2003, focussed on the Web-enabled version of the same system (Mitrovic, Artificial Intelligence in Education, 13(2–4), 173–197, 2003). In this paper, we discuss the reasons for developing the system, our experiences with the early versions, and also provide a history of later projects involving SQL-Tutor."
"The Negotiation of Meaning in Epistemic Situations","International Journal of Artificial Intelligence in Education","volume26","133","149","2016","Baker, M.J. The Negotiation of Meaning in Epistemic Situations. Int J Artif Intell Educ 26, 133–149 (2016). https://doi.org/10.1007/s40593-015-0050-3","This article is a commentary on a model for negotiation in teaching-learning dialogues (Baker 1994) that traces its origins and developments over the past 20 years. The first main section of the paper describes the research background out of which the model arose, within the credo of individualised tutoring of the 1980s. This is followed by a summary of the main elements of the model, then a presentation of its subsequent developments. These comprise the analysis of argumentation dialogue and its potential for collaborative learning, the analysis of interpersonal relations in relation to the interactive regulation of affect, and extensions of the model to other epistemic situations such as explanation generation, co-design, online epistemic discussions and use of communication interfaces in computer-supported collaborative learning environments. On these bases, the object of study of this research is defined as the processes of negotiation of meaning in epistemic situations. It is concluded that the main core of the model was retained, throughout its deepening and extension, but the underlying theory was radically changed, from cognitivist belief-systems to a view of dialogue itself as collective thinking. Two challenges for artificial intelligence and education research are raised: the formalisation of interpersonal relations as they are played out in social interaction, and the analysis of the processes of appropriation of discourse genres."
"Implementation of Motivational Tactics in Tutoring Systems: 20 years on","International Journal of Artificial Intelligence in Education","volume26","170","182","2016","du Boulay, B., del Soldato, T. Implementation of Motivational Tactics in Tutoring Systems: 20 years on. Int J Artif Intell Educ 26, 170–182 (2016). https://doi.org/10.1007/s40593-015-0052-1","This paper describes the development and evaluation of a system called MORE (Motivational Reactive Plan) in the 1990s, designed with an explicit strategy to manage the learner’s motivation on a minute-by-minute basis. Progress since the system was evaluated is outlined and our current thinking on the larger issues of the role that the learner’s values play in motivation as well as issues around “learning how to learn” and meta-motivation is sketched."
"Twenty Years on: Reflections on “Supporting the Use of External Representations in Problem Solving”…","International Journal of Artificial Intelligence in Education","volume26","193","204","2016","Cox, R., Brna, P. Twenty Years on: Reflections on “Supporting the Use of External Representations in Problem Solving”…. Int J Artif Intell Educ 26, 193–204 (2016). https://doi.org/10.1007/s40593-015-0054-z","We reflect upon a paper we wrote that was published in 1995 (20 years ago). We outline the motivation for the work and situate it in the state of the art at that time. We suggest that a key contribution was to highlight the need to provide support for learners who reason with external representations. The support must be flexible enough to accommodate wide individual differences in representational knowledge. In 1995 we saw AIED systems as potentially having several roles; one key role was to enable the learner to move easily from one external representation (ER) to a different one (switching ERs). Other necessary roles included: to seek to use AI to keep several forms of ER in synchrony as the student works on one of them; to guide the student to one ER form (out of several) most likely to be of use; and to help the student use an ER effectively. We outline where our work seems to have had influence and we review progress in the field since 1995. In our conclusion we identify future research agendas that emerge from recent developments in cognitive science."
"Research-Based Design of Pedagogical Agent Roles: a Review, Progress, and Recommendations","International Journal of Artificial Intelligence in Education","volume26","160","169","2016","Kim, Y., Baylor, A.L. Research-Based Design of Pedagogical Agent Roles: a Review, Progress, and Recommendations. Int J Artif Intell Educ 26, 160–169 (2016). https://doi.org/10.1007/s40593-015-0055-y","In this paper we review the contribution of our original work titled “Simulating Instructional Roles Through Pedagogical Agents” published in the International Journal of Artificial Intelligence and Education (Baylor and Kim in Computers and Human Behavior, 25(2), 450–457, 2005). Our original work operationalized three instructional roles as simulated through pedagogical agents, and demonstrated the effectiveness of these agent roles on learning and motivation. Since the publication of our work, pedagogical agent research has expanded its scope from the provision of intelligent guidance to a broad interest in agents’ social and affective support for learners. We discuss current progress in pedagogical agent roles and capabilities, and speculate about the future of agent role design. We expect that optimizing the roles of artificial beings including on-screen agents and robots will continue to interest the educational technology community as these technologies continue to evolve."
"Regulative Loops, Step Loops and Task Loops","International Journal of Artificial Intelligence in Education","volume26","107","112","2016","VanLehn, K. Regulative Loops, Step Loops and Task Loops. Int J Artif Intell Educ 26, 107–112 (2016). https://doi.org/10.1007/s40593-015-0056-x","This commentary suggests a generalization of the conception of the behavior of tutoring systems, which the target article characterized as having an outer loop that was executed once per task and an inner loop that was executed once per step of the task. A more general conception sees these two loops as instances of regulative loops, which repeatedly compare students’ performances to a gold standard and give advice on how to bring that performance closer to the standard."
"Adapting Progress Feedback and Emotional Support to Learner Personality","International Journal of Artificial Intelligence in Education","volume26","877","931","2016","Dennis, M., Masthoff, J. & Mellish, C. Adapting Progress Feedback and Emotional Support to Learner Personality. Int J Artif Intell Educ 26, 877–931 (2016). https://doi.org/10.1007/s40593-015-0059-7","As feedback is an important part of learning and motivation, we investigate how to adapt the feedback of a conversational agent to learner personality (as well as to learner performance, as we expect an interaction effect between personality and performance on feedback). We investigate two aspects of feedback. Firstly, we investigate whether the conversational agent should employ a slant (or bias) in its feedback on particular test scores to motivate a learner with a particular personality trait more effectively (for example, using “you are slightly below expectations” versus “you are substantially below expectations” depending on learner conscientiousness). Secondly, we investigate which emotional support messages the conversational agent should use (for example: using praise, emotional reflection, reassurance or advice) given learner personality and performance. We investigate the adaptation of this feedback to a learner personality, in particular the traits in the Five Factor Model. Five experiments were run where participants gave progress feedback and emotional support to students with different personalities and test scores. The type of emotional support given varied between different personalities (e.g. neurotic individuals with poor grades received more emotional reflection). Two algorithms were created using different methods to describe the adaptations and evaluated on how well they described the experimental data using DICE scores. A refined algorithm was created based on the results. Finally, we ran a qualitative study with teachers to investigate the algorithm’s effectiveness and further refine the algorithm."
"Computer-Based Interaction Analysis with DEGREE Revisited","International Journal of Artificial Intelligence in Education","volume26","113","123","2016","Barros, B., Verdejo, M.F. Computer-Based Interaction Analysis with DEGREE Revisited. Int J Artif Intell Educ 26, 113–123 (2016). https://doi.org/10.1007/s40593-015-0063-y","We review our research with DEGREE and analyse how our work has impacted the collaborative learning community since 2000. Our research is framed within the context of computer-based interaction analysis and the development of computer-supported collaborative learning (CSCL) tools. We identify some aspects of our work which have been followed up by other researchers and highlight some issues that remain pending. Finally we present a perspective of computer-based interaction analysis evolution in relation to a wider technological enhanced learning context."
"Delayed Learning Effects with Erroneous Examples: a Study of Learning Decimals with a Web-Based Tutor","International Journal of Artificial Intelligence in Education","volume25","520","542","2015","McLaren, B.M., Adams, D.M. & Mayer, R.E. Delayed Learning Effects with Erroneous Examples: a Study of Learning Decimals with a Web-Based Tutor. Int J Artif Intell Educ 25, 520–542 (2015). https://doi.org/10.1007/s40593-015-0064-x","Erroneous examples – step-by-step problem solutions with one or more errors for students to find and fix – hold great potential to help students learn. In this study, which is a replication of a prior study (Adams et al. 2014), but with a much larger population (390 vs. 208), middle school students learned about decimals either by working with interactive, web-based erroneous examples or with more traditional supported problems to solve. The erroneous examples group was interactively prompted to find, explain, and fix errors in decimal problems, while the problem-solving group was prompted to solve the same decimal problems and explain their solutions. Both groups were given correctness feedback on their work by the web-based program. Although the two groups did not differ on an immediate post-test, the erroneous examples group performed significantly better on a delayed test, given a week after the initial post-test (d<U+2009>=<U+2009>.33, for gain scores), replicating the pattern of the prior study. Interestingly, the problem solving group reported liking the intervention more than the erroneous examples group (d<U+2009>=<U+2009>.21 for liking rating in a questionnaire) and found the user interface easier to interact with (d<U+2009>=<U+2009>.37), suggesting that what students like does not always lead to the best learning outcomes. This result is consistent with that of desirable difficulty studies, in which a more cognitively challenging learning task results in deeper and longer-lasting learning."
"Face-to-Face Interaction with Pedagogical Agents, Twenty Years Later","International Journal of Artificial Intelligence in Education","volume26","25","36","2016","Johnson, W.L., Lester, J.C. Face-to-Face Interaction with Pedagogical Agents, Twenty Years Later. Int J Artif Intell Educ 26, 25–36 (2016). https://doi.org/10.1007/s40593-015-0065-9","Johnson et al. (International Journal of Artificial Intelligence in Education, 11, 47–78, 2000) introduced and surveyed a new paradigm for interactive learning environments: animated pedagogical agents. The article argued for combining animated interface agent technologies with intelligent learning environments, yielding intelligent systems that can interact with learners in natural, human-like ways to achieve better learning outcomes. We outlined a variety of possible uses for pedagogical agents. But we offered only preliminary evidence that they improve learning, leaving that to future research and development. Twenty years have elapsed since work began on animated pedagogical agents. This article re-examines the concepts and predictions in the 2000 article in the context of the current state of the field. Some of the ideas in the paper have become well established and widely adopted, especially in game-based learning environments. Others are only now being realized, thanks to advances in immersive interfaces and robotics that enable rich face-to-face interaction between learners and agents. Research has confirmed that pedagogical agents can be beneficial, but not equally for all learning problems, applications, and learner populations. Although there is a growing body of research findings about pedagogical agents, many questions remain and much work remains to be done."
"ELM-ART – An Interactive and Intelligent Web-Based Electronic Textbook","International Journal of Artificial Intelligence in Education","volume26","72","81","2016","Weber, G., Brusilovsky, P. ELM-ART – An Interactive and Intelligent Web-Based Electronic Textbook. Int J Artif Intell Educ 26, 72–81 (2016). https://doi.org/10.1007/s40593-015-0066-8","This paper present provides a broader view on ELM-ART, one of the first Web-based Intelligent Educational systems that offered a creative combination of two different paradigms - Intelligent Tutoring and Adaptive Hypermedia technologies. The unique dual nature of ELM-ART contributed to its long life and research impact and was a result of collaboration of two researchers with complementary ideas supported by talented students and innovative Web software. The authors present a brief account of this collaborative work and its outcomes. We start with explaining the “roots” of ELM-ART, explain the emergence of the “intelligent textbook” paradigm behind the system, and discuss the follow-up and the impact of the original project."
"Reflections on Andes’ Goal-free User Interface","International Journal of Artificial Intelligence in Education","volume26","82","90","2016","VanLehn, K. Reflections on Andes’ Goal-free User Interface. Int J Artif Intell Educ 26, 82–90 (2016). https://doi.org/10.1007/s40593-015-0067-7","Although the Andes project produced many results over its 18 years of activity, this commentary focuses on its contributions to understanding how a goal-free user interface impacts the overall design and performance of a step-based tutoring system. Whereas a goal-aligned user interface displays relevant goals as blank boxes or empty locations that the student needs to fill with specific content, a goal-free user interface is essentially a blank canvas, with no visual indications of the goals that should be attempted next. This commentary also briefly mentions work that occurred after the “final” report on Andes appeared in this journal in 2005. The newer work focused on getting students to ask for hints when they need them."
"The Affective Experience of Novice Computer Programmers","International Journal of Artificial Intelligence in Education","volume27","181","206","2017","Bosch, N., D’Mello, S. The Affective Experience of Novice Computer Programmers. Int J Artif Intell Educ 27, 181–206 (2017). https://doi.org/10.1007/s40593-015-0069-5","Novice students (N<U+2009>=<U+2009>99) participated in a lab study in which they learned the fundamentals of computer programming in Python using a self-paced computerized learning environment involving a 25-min scaffolded learning phase and a 10-min unscaffolded fadeout phase. Students provided affect judgments at approximately 100 points (every 15 s) over the course of viewing videos of their faces and computer screens recorded during the learning session. The results indicated that engagement, confusion, frustration, boredom, and curiosity were the most frequent affective states, while anxiety, happiness, anger, surprise, disgust, sadness, and fear were rare. Confusion + frustration and curiosity + engagement were identified as two frequently co-occurring pairs of affective states. An analysis of affect dynamics indicated that there were reciprocal transitions between engagement and confusion, confusion and frustration, and one way transitions between frustration and boredom and boredom and engagement. Considering interaction events in tandem with affect revealed that constructing code was the central activity that preceded and followed each affective state. Further, confusion and frustration followed errors and preceded hint usage, while curiosity and engagement followed reading or coding. An analysis of affect-learning relationships after partialling out control variables (e.g., scholastic aptitude, hint usage) indicated that boredom (r<U+2009>=<U+2009>-.149) and frustration (r<U+2009>=<U+2009>-.218) were negative correlated with learning while transitions between confusion <U+2192> frustration (r<U+2009>=<U+2009>.103), frustration <U+2192> confusion (r<U+2009>=<U+2009>.105), and boredom <U+2192> engagement (r<U+2009>=<U+2009>.282) were positively correlated with learning. Implications of the results to theory on affect incidence and dynamics and on the design of affect-aware learning environments are discussed."
"Data-Driven Hint Generation in Vast Solution Spaces: a Self-Improving Python Programming Tutor","International Journal of Artificial Intelligence in Education","volume27","37","64","2017","Rivers, K., Koedinger, K.R. Data-Driven Hint Generation in Vast Solution Spaces: a Self-Improving Python Programming Tutor. Int J Artif Intell Educ 27, 37–64 (2017). https://doi.org/10.1007/s40593-015-0070-z","To provide personalized help to students who are working on code-writing problems, we introduce a data-driven tutoring system, ITAP (Intelligent Teaching Assistant for Programming). ITAP uses state abstraction, path construction, and state reification to automatically generate personalized hints for students, even when given states that have not occurred in the data before. We provide a detailed description of the system’s implementation and perform a technical evaluation on a small set of data to determine the effectiveness of the component algorithms and ITAP’s potential for self-improvement. The results show that ITAP is capable of producing hints for almost any given state after being given only a single reference solution, and that it can improve its performance by collecting data over time."
"Shifting the Load: a Peer Dialogue Agent that Encourages its Human Collaborator to Contribute More to Problem Solving","International Journal of Artificial Intelligence in Education","volume27","101","129","2017","Howard, C., Jordan, P., Di Eugenio, B. et al. Shifting the Load: a Peer Dialogue Agent that Encourages its Human Collaborator to Contribute More to Problem Solving. Int J Artif Intell Educ 27, 101–129 (2017). https://doi.org/10.1007/s40593-015-0071-y","Despite a growing need for educational tools that support students at the earliest phases of undergraduate Computer Science (CS) curricula, relatively few such tools exist–the majority being Intelligent Tutoring Systems. Since peer interactions more readily give rise to challenges and negotiations, another way in which students can become more interactive during problem solving, we created an artificial peer collaborator to determine its value for aiding CS students. Central to its development was the notion that it should monitor the student’s collaborative behavior and attempt to guide him/her towards more productive behavior. In prior work, we found that initiative shifts correlate with both Knowledge Co-Construction (KCC) and learning and are potentially easier to model as an indicator of productive collaboration in instructional software. In this paper, we describe a unique peer dialogue agent that we created to test the effects of tracking and reacting to initiative shifts. While our study did not find differences in learning gains when comparing agents that do and do not track and react to initiative shifts, we did find that students do learn when interacting with the agent and that attempting to influence initiative taking did make a difference. This suggests that by tracking initiative shifts, the agent was able to detect times when the student had been letting the agent do most of the “deep thinking” and that the agent’s tactics for encouraging the student to begin taking the initiative again were helpful."
"Commentary on: “Toward Computer-Based Support of MetaCognitive Skills: a Computational Framework to Coach Self Explanation”","International Journal of Artificial Intelligence in Education","volume26","183","192","2016","Conati, C. Commentary on: “Toward Computer-Based Support of MetaCognitive Skills: a Computational Framework to Coach Self Explanation”. Int J Artif Intell Educ 26, 183–192 (2016). https://doi.org/10.1007/s40593-015-0074-8","This paper is a commentary on “Toward Computer-Based Support of Meta-Cognitive Skills: a Computational Framework to Coach Self-Explanation”, by Cristina Conati and Kurt Vanlehn, published in the IJAED in 2000 (Conati and VanLehn 2010). This work was one of the first examples of Intelligent Learning Environments (ILE) that target activities beyond problem solving doing so by providing adaptive support to apply relevant domain independent meta-cognitive skills, as opposed to targeting domain-dependent knowledge. We provide an overview of the SE-Coach, the ILE presented in (Conati and Vanlehn 2000), in terms of underlying motivation, objectives, appeach and contibutions. This overview is followed by a discussion of subsequent developments in research on providing intelligent, student-adaptive support to meta-cognition, as well as of remaining open issues and avenues for future research."
"Coordinating the Complexity of Tools, Tasks, and Users: On Theory-based Approaches to Authoring Tool Usability","International Journal of Artificial Intelligence in Education","volume26","37","71","2016","Murray, T. Coordinating the Complexity of Tools, Tasks, and Users: On Theory-based Approaches to Authoring Tool Usability. Int J Artif Intell Educ 26, 37–71 (2016). https://doi.org/10.1007/s40593-015-0076-6","Intelligent Tutoring Systems authoring tools are highly complex educational software applications used to produce highly complex software applications (i.e. ITSs). How should our assumptions about the target users (authors) impact the design of authoring tools? In this article I first reflect on the factors leading to my original 1999 article on the state of the art in ITS authoring tools and consider some challenges facing authoring tool researchers today. Then, in the bulk of the paper, I propose some principled foundations for future authoring tool design, focusing on operationalizing the construct of complexity—for tool, task, and user. ITS authoring tools are major undertakings and to redeem this investment it is important to anticipate actual user needs and capacities. I propose that one way to do this is to match the complexity of tool design to the complexity of authoring tasks and the complexity capacity of users and user communities. Doing so entails estimating the complexity of the mental models that a user is expected to build in order to use a tool as intended. The goal is not so much to support the design of more powerful authoring tools as it is to design tools that meet the needs of realistic user audiences. This paper presents some exploratory ideas on how to operationalize the concept of complexity for tool, task, and user. The paper draws from the following theories and frameworks to weave this narrative: Complexity Science, Activity Theory, Epistemic Forms and Games, and adult cognitive developmental theory (Hierarchical Complexity Theory). This exploration of usability and complexity is applicable to the design of any type of complex authoring application, though the application area that motivated the exploration is ITS authoring."
"Using Ontological Engineering to Overcome AI-ED Problems: Contribution, Impact and Perspectives","International Journal of Artificial Intelligence in Education","volume26","91","106","2016","Mizoguchi, R., Bourdeau, J. Using Ontological Engineering to Overcome AI-ED Problems: Contribution, Impact and Perspectives. Int J Artif Intell Educ 26, 91–106 (2016). https://doi.org/10.1007/s40593-015-0077-5","This article reflects on the ontology engineering methodology discussed by the paper entitled “Using Ontological Engineering to Overcome AI-ED Problems” published in this journal in 2000. We discuss the achievements obtained in the last 10 years, the impact of our work as well as recent trends and perspectives in ontology engineering for AIED."
"The SIETTE Automatic Assessment Environment","International Journal of Artificial Intelligence in Education","volume26","270","292","2016","Conejo, R., Guzmán, E. & Trella, M. The SIETTE Automatic Assessment Environment. Int J Artif Intell Educ 26, 270–292 (2016). https://doi.org/10.1007/s40593-015-0078-4","This article describes the evolution and current state of the domain-independent Siette assessment environment. Siette supports different assessment methods—including classical test theory, item response theory, and computer adaptive testing—and integrates them with multidimensional student models used by intelligent educational systems. Teachers can use an authoring tool to create large item pools of different types of questions, including multiple choice, open answer, generative questions, and complex tasks. Siette can be used for formative and summative assessment and incorporates different learning elements, including scaffolding features, such as hints, feedback, and misconceptions. It includes numerous other features covering different educational needs and techniques, such as spaced repetition, collaborative testing, or pervasive learning. Siette is designed as a web-based assessment component that can be semantically integrated with intelligent systems or with large LMSs, such as Moodle. This article reviews the evolution of the Siette system, presents information on its use, and analyses this information from a broader and critical perspective on the use of intelligent systems in education."
"Lab4CE: a Remote Laboratory for Computer Education","International Journal of Artificial Intelligence in Education","volume27","154","180","2017","Broisin, J., Venant, R. & Vidal, P. Lab4CE: a Remote Laboratory for Computer Education. Int J Artif Intell Educ 27, 154–180 (2017). https://doi.org/10.1007/s40593-015-0079-3","Remote practical activities have been demonstrated to be efficient when learners come to acquire inquiry skills. In computer science education, virtualization technologies are gaining popularity as this technological advance enables instructors to implement realistic practical learning activities, and learners to engage in authentic and problem-based learning. However, virtualization solutions have not been designed especially for education and do not address any pedagogical concern. Since several large-scale studies showed that instructional supports during practical activities are almost as important as technical features, this article investigates the following research question: how the scaffolding around the lab increases students’ engagement in remote practical learning of computer science? To answer this question, we introduce the Lab4CE environment, a remote laboratory for computer education which adopts a distributed, modular and flexible architecture to integrate a set of scaffolding tools and services intended for instructors and learners. An exploratory study conducted with 139 undergraduate students enrolled in the first year of a computer science degree suggests a positive effect of the framework on learners’ engagement when they come to practice system administration, and reveals a significant positive correlation between students’ activity within the system and students’ learning achievement."
"Ask-Elle: an Adaptable Programming Tutor for Haskell Giving Automated Feedback","International Journal of Artificial Intelligence in Education","volume27","65","100","2017","Gerdes, A., Heeren, B., Jeuring, J. et al. Ask-Elle: an Adaptable Programming Tutor for Haskell Giving Automated Feedback. Int J Artif Intell Educ 27, 65–100 (2017). https://doi.org/10.1007/s40593-015-0080-x","Ask-Elle is a tutor for learning the higher-order, strongly-typed functional programming language Haskell. It supports the stepwise development of Haskell programs by verifying the correctness of incomplete programs, and by providing hints. Programming exercises are added to Ask-Elle by providing a task description for the exercise, one or more model solutions, and properties that a solution should satisfy. The properties and model solutions can be annotated with feedback messages, and the amount of flexibility that is allowed in student solutions can be adjusted. The main contribution of our work is the design of a tutor that combines (1) the incremental development of different solutions in various forms to a programming exercise with (2) automated feedback and (3) teacher-specified programming exercises, solutions, and properties. The main functionality is obtained by means of strategy-based model tracing and property-based testing. We have tested the feasibility of our approach in several experiments, in which we analyse both intermediate and final student solutions to programming exercises, amongst others."
"Interaction with an Edu-Game: A Detailed Analysis of Student Emotions and Judges’ Perceptions","International Journal of Artificial Intelligence in Education","volume26","975","1010","2016","Conati, C., Gutica, M. Interaction with an Edu-Game: A Detailed Analysis of Student Emotions and Judges’ Perceptions. Int J Artif Intell Educ 26, 975–1010 (2016). https://doi.org/10.1007/s40593-015-0081-9","We present the results of a study that explored the emotions experienced by students during interaction with an educational game for math (Heroes of Math Island). Starting from emotion frameworks in affective computing and education, we considered a larger set of emotions than in related research. For emotion labeling, we started from a standard methodology that relies on trained judges to report emotions over 20-s intervals, however, we asked judges to report all observed emotions in each interval, as opposed to only choosing one, as is standard practice. This variation allows us to discuss the appropriateness of this interval for emotion labeling. We present a detailed analysis of interrater reliability, both aggregated and over individual students, that considers not only labeling agreement among judges in terms of emotion type, but also with respect to the number of emotions detected. We also provide an analysis based on in-depth one-to-one interviews with judges, to gain insights on the challenges they encountered in labeling emotions."
"An Interview Reflection on “Intelligent Tutoring Goes to School in the Big City”","International Journal of Artificial Intelligence in Education","volume26","13","24","2016","Koedinger, K.R., Aleven, V. An Interview Reflection on “Intelligent Tutoring Goes to School in the Big City”. Int J Artif Intell Educ 26, 13–24 (2016). https://doi.org/10.1007/s40593-015-0082-8","Our 1997 article in IJAIED reported on a study that showed that a new algebra curriculum with an embedded intelligent tutoring system (the Algebra Cognitive Tutor) dramatically enhanced high-school students’ learning. The main motivation for the study was to demonstrate that intelligent tutors that have cognitive science research embedded in them could have real impact in schools. This study was one of the first large-scale classroom evaluations of the integrated use of an Intelligent Tutoring System (ITS) in high schools. A core challenge was figuring out how to embed this new technology into a curriculum and into the existing social context of schools. A key element of the study design was to include multiple kinds of assessments, including standardized test items and items measuring complex problem solving and use of representations. The results were powerful: “On average the 470 students in experimental classes outperformed students in comparison classes by 15 % on standardized tests and 100 % on tests targeting the [course] objectives.” We suggested that the study was evidence “that laboratory tutoring systems can be scaled up and made to work, both technically and pedagogically, in real and unforgiving settings like urban high schools.” Since this study, many more classroom studies comparing instruction that includes an ITS against business as usual have been conducted, often showing advantages for the ITS-enhanced curricula. More rigorous randomized field trials are now more commonplace, but the approach of using multiple assessments in large-scale randomized field trials has not caught on. Cognitive task analysis will remain fundamental to the success of ITSs. A key remaining question for ITS is to find out how they can be used most effectively to support open-ended problem solving, either online or offline. Given all the recent excitement around Massive Open Online Courses (MOOCs), it is interesting to note that our field of Artificial Intelligence in Education has been making huge, less recognized, progress with impact on millions of students and with the majority of those students finishing the course!"
"Taking Control: Stealth Assessment of Deterministic Behaviors Within a Game-Based System","International Journal of Artificial Intelligence in Education","volume26","1011","1032","2016","Snow, E.L., Likens, A.D., Allen, L.K. et al. Taking Control: Stealth Assessment of Deterministic Behaviors Within a Game-Based System. Int J Artif Intell Educ 26, 1011–1032 (2016). https://doi.org/10.1007/s40593-015-0085-5","Game-based environments frequently afford students the opportunity to exert agency over their learning paths by making various choices within the environment. The combination of log data from these systems and dynamic methodologies may serve as a stealth means to assess how students behave (i.e., deterministic or random) within these learning environments. The current work captures variations in students’ behavior patterns by employing two dynamic analyses to classify students’ sequences of choices within an adaptive learning environment. Random Walk analyses and Hurst exponents were used to classify students’ interaction patterns as random or deterministic. Forty high school students interacted with the game-based system, iSTART-ME, for 11-sessions (pretest, 8 training sessions, posttest, and a delayed retention test). Analyses revealed that students who interacted in a more deterministic manner also generated higher quality self-explanations during training sessions. The results point toward the potential for dynamic analyses such as random walk analyses and Hurst exponents to provide stealth assessments of students’ learning behaviors while engaged within a game-based environment."
"Conversations with AutoTutor Help Students Learn","International Journal of Artificial Intelligence in Education","volume26","124","132","2016","Graesser, A.C. Conversations with AutoTutor Help Students Learn. Int J Artif Intell Educ 26, 124–132 (2016). https://doi.org/10.1007/s40593-015-0086-4","AutoTutor helps students learn by holding a conversation in natural language. AutoTutor is adaptive to the learners’ actions, verbal contributions, and in some systems their emotions. Many of AutoTutor’s conversation patterns simulate human tutoring, but other patterns implement ideal pedagogies that open the door to computer tutors eclipsing human tutors in learning gains. Indeed, current versions of AutoTutor yield learning gains on par with novice and expert human tutors. This article selectively highlights the status of AutoTutor’s dialogue moves, learning gains, implementation challenges, differences between human and ideal tutors, and some of the systems that evolved from AutoTutor. Current and future AutoTutor projects are investigating three-party conversations, called trialogues, where two agents (such as a tutor and student) interact with the human learner."
"Example-Tracing Tutors: Intelligent Tutor Development for Non-programmers","International Journal of Artificial Intelligence in Education","volume26","224","269","2016","Aleven, V., McLaren, B.M., Sewall, J. et al. Example-Tracing Tutors: Intelligent Tutor Development for Non-programmers. Int J Artif Intell Educ 26, 224–269 (2016). https://doi.org/10.1007/s40593-015-0088-2","In 2009, we reported on a new Intelligent Tutoring Systems (ITS) technology, example-tracing tutors, that can be built without programming using the Cognitive Tutor Authoring Tools (CTAT). Creating example-tracing tutors was shown to be 4–8 times as cost-effective as estimates for ITS development from the literature. Since 2009, CTAT and its associated learning management system, the Tutorshop, have been extended and have been used for both research and real-world instruction. As evidence that example-tracing tutors are an effective and mature ITS paradigm, CTAT-built tutors have been used by approximately 44,000 students and account for 40 % of the data sets in DataShop, a large open repository for educational technology data sets. We review 18 example-tracing tutors built since 2009, which have been shown to be effective in helping students learn in real educational settings, often with large pre/post effect sizes. These tutors support a variety of pedagogical approaches, beyond step-based problem solving, including collaborative learning, educational games, and guided invention activities. CTAT and other ITS authoring tools illustrate that non-programmer approaches to building ITS are viable and useful and will likely play a key role in making ITS widespread."
"Help Helps, But Only So Much: Research on Help Seeking with Intelligent Tutoring Systems","International Journal of Artificial Intelligence in Education","volume26","205","223","2016","Aleven, V., Roll, I., McLaren, B.M. et al. Help Helps, But Only So Much: Research on Help Seeking with Intelligent Tutoring Systems. Int J Artif Intell Educ 26, 205–223 (2016). https://doi.org/10.1007/s40593-015-0089-1","Help seeking is an important process in self-regulated learning (SRL). It may influence learning with intelligent tutoring systems (ITSs), because many ITSs provide help, often at the student’s request. The Help Tutor was a tutor agent that gave in-context, real-time feedback on students’ help-seeking behavior, as they were learning with an ITS. Key goals were to help students become better self-regulated learners and help them achieve better domain-level learning outcomes. In a classroom study, feedback on help seeking helped students to use on-demand help more deliberately, even after the feedback was no longer given, but not to achieve better learning outcomes. The work made a number of contributions, including the creation of a knowledge-engineered, rule-based, executable model of help seeking that can drive tutoring. We review these contributions from a contemporary perspective, with a theoretical analysis, a review of recent empirical literature on help seeking with ITSs, and methodological suggestions. Although we do not view on-demand, principle-based help during tutored problem solving as being as important as we once did, we still view it as helpful under certain circumstances, and recommend that it be included in ITSs. We view the goal of helping students become better self-regulated learners as one of the grand challenges in ITSs research today."
"Do You Think You Can? The Influence of Student Self-Efficacy on the Effectiveness of Tutorial Dialogue for Computer Science","International Journal of Artificial Intelligence in Education","volume27","130","153","2017","Wiggins, J.B., Grafsgaard, J.F., Boyer, K.E. et al. Do You Think You Can? The Influence of Student Self-Efficacy on the Effectiveness of Tutorial Dialogue for Computer Science. Int J Artif Intell Educ 27, 130–153 (2017). https://doi.org/10.1007/s40593-015-0091-7","In recent years, significant advances have been made in intelligent tutoring systems, and these advances hold great promise for adaptively supporting computer science (CS) learning. In particular, tutorial dialogue systems that engage students in natural language dialogue can create rich, adaptive interactions. A promising approach to increasing the effectiveness of these systems is to adapt not only to problem-solving performance, but also to a student’s characteristics. Self-efficacy refers to a student’s view of her ability to complete learning objectives and to achieve goals; this characteristic may be particularly influential during tutorial dialogue for computer science education. This article examines a corpus of effective human tutoring for computer science to discover the extent to which considering self-efficacy as measured within a pre-survey, coupled with dialogue and task events during tutoring, improves models that predict the student’s self-reported frustration and learning gains after tutoring. The analysis reveals that students with high and low self-efficacy benefit differently from tutorial dialogue. Student control, social dialogue, and tutor moves to increase efficiency, may be particularly helpful for high self-efficacy students, while for low self-efficacy students, guided experimentation may foster greater learning while at the same time potentially increasing frustration. It is hoped that this line of research will enable tutoring systems for computer science to tailor their tutorial interactions more effectively."
"Learning Science by Constructing Models: Can Dragoon Increase Learning without Increasing the Time Required?","International Journal of Artificial Intelligence in Education","volume26","1033","1068","2016","VanLehn, K., Chung, G., Grover, S. et al. Learning Science by Constructing Models: Can Dragoon Increase Learning without Increasing the Time Required?. Int J Artif Intell Educ 26, 1033–1068 (2016). https://doi.org/10.1007/s40593-015-0093-5","A common hypothesis is that students will more deeply understand dynamic systems and other complex phenomena if they construct computational models of them. Attempts to demonstrate the advantages of model construction have been stymied by the long time required for students to acquire skill in model construction. In order to make model construction a feasible vehicle for science instruction, the Dragoon system combined three simplifications: (1) a simple notation for models of dynamic systems, (2) a step-based tutoring system, and (3) problems that described the model to be constructed as well as the system represented by the model. In order to test whether these simplifications reduced the time for learning how to construct models while preserving the benefits of model construction over baseline instruction, three classroom studies were conducted. All studies were experiments, in that they compared classes using Dragoon to classes learning the same material without Dragoon. However, as classroom studies, they could not tightly control all sources of variation. The first study produced null results, but it compared learning across just one class period. The second study in 4 high school science classes showed that instruction based on Dragoon cost only one extra class period (about 50 min) out of 4 class periods and was more effective than the same content taught without Dragoon. A third study in 3 more high school science classes, where 2 Dragoon classes and 1 non-Dragoon class met for the same number of class periods, showed that Dragoon was more effective than the same content taught without Dragoon. The effect sizes were moderately large on both an open response test (d<U+2009>=<U+2009>1.00) and a concept mapping task (d<U+2009>=<U+2009>0.49). Thus, it appears that our efforts have simplified model construction to the point that it can be used in science instruction with no additional class time needed, and yet it still seems to be more effective than the same instruction done without model construction."
"The Future of Adaptive Learning: Does the Crowd Hold the Key?","International Journal of Artificial Intelligence in Education","volume26","615","644","2016","Heffernan, N.T., Ostrow, K.S., Kelly, K. et al. The Future of Adaptive Learning: Does the Crowd Hold the Key?. Int J Artif Intell Educ 26, 615–644 (2016). https://doi.org/10.1007/s40593-016-0094-z","Due to substantial scientific and practical progress, learning technologies can effectively adapt to the characteristics and needs of students. This article considers how learning technologies can adapt over time by crowdsourcing contributions from teachers and students – explanations, feedback, and other pedagogical interactions. Considering the context of ASSISTments, an online learning platform, we explain how interactive mathematics exercises can provide the workflow necessary for eliciting feedback contributions and evaluating those contributions, by simply tapping into the everyday system usage of teachers and students. We discuss a series of randomized controlled experiments that are currently running within ASSISTments, with the goal of establishing proof of concept that students and teachers can serve as valuable resources for the perpetual improvement of adaptive learning technologies. We also consider how teachers and students can be motivated to provide such contributions, and discuss the plans surrounding PeerASSIST, an infrastructure that will help ASSISTments to harness the power of the crowd. Algorithms from machine learning (i.e., multi-armed bandits) will ideally provide a mechanism for managerial control, allowing for the automatic evaluation of contributions and the personalized provision of the highest quality content. In many ways, the next 25 years of adaptive learning technologies will be driven by the crowd, and this article serves as the road map that ASSISTments has chosen to follow."
"Letting Artificial Intelligence in Education Out of the Box: Educational Cobots and Smart Classrooms","International Journal of Artificial Intelligence in Education","volume26","701","712","2016","Timms, M.J. Letting Artificial Intelligence in Education Out of the Box: Educational Cobots and Smart Classrooms. Int J Artif Intell Educ 26, 701–712 (2016). https://doi.org/10.1007/s40593-016-0095-y","This paper proposes that the field of AIED is now mature enough to break away from being delivered mainly through computers and pads so that it can engage with students in new ways and help teachers to teach more effectively. Mostly, the intelligent systems that AIED has delivered so far have used computers and other devices that were essentially designed for businesses or personal use, and not specifically for education. The future holds the promise of creating technologies designed specifically for learning and teaching by combining the power of AIED with advances in the field of robotics and in the increasing use of sensor devices to monitor our surroundings and actions. The paper assumes that “schools” (i.e., a place where children will gather to learn) will still exist in some shape or form in 25 years and that teachers will continue to oversee and promote learning among the students. It proposes that there will be educational cobots assisting teachers in the classrooms of tomorrow and provides examples from current work in robotics. It also envisions smart classrooms that make use of sensors to support learning and illustrates how they might be used in new ways if AIED applications are embedded into them."
"Optimists’ Creed: Brave New Cyberlearning, Evolving Utopias (Circa 2041)","International Journal of Artificial Intelligence in Education","volume26","796","808","2016","Burleson, W., Lewis, A. Optimists’ Creed: Brave New Cyberlearning, Evolving Utopias (Circa 2041). Int J Artif Intell Educ 26, 796–808 (2016). https://doi.org/10.1007/s40593-016-0096-x","This essay imagines the role that artificial intelligence innovations play in the integrated living, learning and research environments of 2041. Here, in 2041, in the context of increasingly complex wicked challenges, whose solutions by their very nature continue to evade even the most capable experts, society and technology have co-evolved to embrace cyberlearning as an essential tool for envisioning and refining utopias–non-existent societies described in considerable detail. Our society appreciates that evolving these utopias is critical to creating and resolving wicked challenges and to better understanding how to create a world in which we are actively “learning to be” – deeply engaged in intrinsically motivating experiences that empower each of us to reach our full potential. Since 2015, Artificial Intelligence in Education (AIED) has transitioned from what was primarily a research endeavour, with educational impact involving millions of user/learners, to serving, now, as a core contributor to democratizing learning (Dewey 2004) and active citizenship for all (billions of learners throughout their lives). An expansive experiential super computing cyberlearning environment, we affectionately call the “Holodeck,” supports transdisciplinary collaboration and integrated education, research, and innovation, providing a networked software/hardware infrastructure that synthesizes visual, audio, physical, social, and societal components. The Holodeck’s large-scale integration of learning, research, and innovation, through real-world problem solving and teaching others what you have learned, effectively creates a global meritocratic network with the potential to resolve society’s wicked challenges while empowering every citizen to realize her or his full potential."
"Perceived Task-Difficulty Recognition from Log-file Information for the Use in Adaptive Intelligent Tutoring Systems","International Journal of Artificial Intelligence in Education","volume26","855","876","2016","Janning, R., Schatten, C. & Schmidt-Thieme, L. Perceived Task-Difficulty Recognition from Log-file Information for the Use in Adaptive Intelligent Tutoring Systems. Int J Artif Intell Educ 26, 855–876 (2016). https://doi.org/10.1007/s40593-016-0097-9","Recognising students’ emotion, affect or cognition is a relatively young field and still a challenging task in the area of intelligent tutoring systems. There are several ways to use the output of these recognition tasks within the system. The approach most often mentioned in the literature is using it for giving feedback to the students. The features used for that approach can be high-level features like linguistics features which are words related to emotions or affects, taken e.g. from written or spoken inputs, or low-level features like log-file features which are created from information contained in the log-files. In this work we aim at supporting task sequencing by perceived task-difficulty recognition on low-level features easily extracted from the log-file. We analyse these features by statistical tests showing that there are statistically significant feature combinations and hence the presented features are able to describe students’ perceived task-difficulty in intelligent tutoring systems. Furthermore, we apply different classification methods to the log-file features for perceived task-difficulty recognition and present a kind of higher ensemble method for improving the classification performance on the features extracted from a real data set. The presented approach outperforms classical ensemble methods and is able to improve the classification performance substantially, enabling a perceived task-difficulty recognition satisfactory enough for employing its output for components of a real system like task independent support or task sequencing."
"ITS, The End of the World as We Know It: Transitioning AIED into a Service-Oriented Ecosystem","International Journal of Artificial Intelligence in Education","volume26","756","770","2016","Nye, B.D. ITS, The End of the World as We Know It: Transitioning AIED into a Service-Oriented Ecosystem. Int J Artif Intell Educ 26, 756–770 (2016). https://doi.org/10.1007/s40593-016-0098-8","Advanced learning technologies are reaching a new phase of their evolution where they are finally entering mainstream educational contexts, with persistent user bases. However, as AIED scales, it will need to follow recent trends in service-oriented and ubiquitous computing: breaking AIED platforms into distinct services that can be composed for different platforms (web, mobile, etc.) and distributed across multiple systems. This will represent a move from learning platforms to an ecosystem of interacting learning tools. Such tools will enable new opportunities for both user-adaptation and experimentation. Traditional macro-adaptation (problem selection) and step-based adaptation (hints and feedback) will be extended by meta-adaptation (adaptive system selection) and micro-adaptation (event-level optimization). The existence of persistent and widely-used systems will also support new paradigms for experimentation in education, allowing researchers to understand interactions and boundary conditions for learning principles. New central research questions for the field will also need to be answered due to these changes in the AIED landscape."
"Another 25 Years of AIED? Challenges and Opportunities for Intelligent Educational Technologies of the Future","International Journal of Artificial Intelligence in Education","volume26","771","783","2016","Pinkwart, N. Another 25 Years of AIED? Challenges and Opportunities for Intelligent Educational Technologies of the Future. Int J Artif Intell Educ 26, 771–783 (2016). https://doi.org/10.1007/s40593-016-0099-7","This paper attempts an analysis of some current trends and future developments in computer science, education, and educational technology. Based on these trends, two possible future predictions of AIED are presented in the form of a utopian vision and a dystopian vision. A comparison of these two visions leads to seven challenges that AIED might have to face in the future: intercultural and global dimensions, practical impact, privacy, interaction methods, collaboration at scale, effectiveness in multiple domains, and the role of AIED in educational technology. The paper discusses these challenges and the associated risks and opportunities."
"We’re in this Together: Intentional Design of Social Relationships with AIED Systems","International Journal of Artificial Intelligence in Education","volume26","713","729","2016","Walker, E., Ogan, A. We’re in this Together: Intentional Design of Social Relationships with AIED Systems. Int J Artif Intell Educ 26, 713–729 (2016). https://doi.org/10.1007/s40593-016-0100-5","Students’ relationships with their peers, teachers, and communities influence the ways in which they approach learning activities and the degree to which they benefit from them. Learning technologies, ranging from humanoid robots to text-based prompts on a computer screen, have a similar social influence on students. We envision a future in which AIED systems adaptively create social relationships with their learners in addition to modeling student learning and providing adaptive cognitive support. By deliberate design of the relationships between learners and systems, the systems can have maximal impact on student learning and engagement. This deliberate design would include careful consideration of the type of learning technology and its channels of communication with the learner, the broader context of the interaction, and the history of the relationship between the student and the learning technology. To achieve this vision, as a field, we will need to build understanding of how relationships form in human-technology settings, and how educational technologies should be advanced to support the assessment and monitoring of meaningful relationship factors over time."
"AI as a Methodology for Supporting Educational Praxis and Teacher Metacognition","International Journal of Artificial Intelligence in Education","volume26","679","700","2016","Porayska-Pomsta, K. AI as a Methodology for Supporting Educational Praxis and Teacher Metacognition. Int J Artif Intell Educ 26, 679–700 (2016). https://doi.org/10.1007/s40593-016-0101-4","Evidence-based practice (EBP) is of critical importance in education where emphasis is placed on the need to equip educators with an ability to independently generate and reflect on evidence of their practices in situ – a process also known as praxis. This paper examines existing research related to teachers’ metacognitive skills and, using two exemplar projects, it discusses the utility and relevance of AI methods of knowledge representation and knowledge elicitation as methodologies for supporting EBP. Research related to technology-enhanced communities of practice as a means for teachers to share and compare their knowledge with others is also examined. Suggestions for the key considerations in supporting teachers’ metacognition in praxis are made based on the review of literature and discussion of the specific projects, with the aim to highlight potential future research directions for AIEd. A proposal is made that a crucial part of AIEd’s future resides in its curating the role of AI as a methodology for supporting teacher training and continuous professional development, especially as relates to their developing metacognitive skills in relation to their practices."
"Different Futures of Adaptive Collaborative Learning Support","International Journal of Artificial Intelligence in Education","volume26","784","795","2016","Rummel, N., Walker, E. & Aleven, V. Different Futures of Adaptive Collaborative Learning Support. Int J Artif Intell Educ 26, 784–795 (2016). https://doi.org/10.1007/s40593-016-0102-3","In this position paper we contrast a Dystopian view of the future of adaptive collaborative learning support (ACLS) with a Utopian scenario that – due to better-designed technology, grounded in research – avoids the pitfalls of the Dystopian version and paints a positive picture of the practice of computer-supported collaborative learning 25 years from now. We discuss research that we see as important in working towards a Utopian future in the next 25 years. In particular, we see a need to work towards a comprehensive instructional framework building on educational theory. This framework will allow us to provide nuanced and flexible (i.e. intelligent) ACLS to collaborative learners – the type of support we sketch in our Utopian scenario."
"Training the Body: The Potential of AIED to Support Personalized Motor Skills Learning","International Journal of Artificial Intelligence in Education","volume26","730","755","2016","Santos, O.C. Training the Body: The Potential of AIED to Support Personalized Motor Skills Learning. Int J Artif Intell Educ 26, 730–755 (2016). https://doi.org/10.1007/s40593-016-0103-2","This paper argues that the research field of Artificial Intelligence in Education (AIED) can benefit from integrating recent technological advances (e.g., wearable devices, big data processing, 3D modelling, 3D printing, ambient intelligence) and design methodologies, such as TORMES, when developing systems that address the psychomotor learning domain. In particular, the acquisition of motor skills could benefit from individualized instruction and support just as cognitive skills learning has over the last decades. To this point, procedural learning has been considered since the earliest days of AIED (dating back to the 1980’s). However, AIED developments in motor skills learning have lagged significantly behind. As technology has evolved, and supported by the do-it-yourself and quantified-self movements, it is now possible to integrate emerging interactive technologies in order to provide personal awareness and reflection for behavioural change at low cost and with low intrusion. Many activities exist that would benefit from personalizing motor skills learning, such as playing a musical instrument, handwriting, drawing, training for surgery, improving the technique in sports and martial arts, learning sign language, dancing, etc. In this context, my suggestions for AIED research in the coming 25 years focus on addressing challenges regarding 1) modelling the psychomotor interaction, and 2) providing appropriate personalized psychomotor support."
"Giving Eyesight to the Blind: Towards Attention-Aware AIED","International Journal of Artificial Intelligence in Education","volume26","645","659","2016","D’Mello, S.K. Giving Eyesight to the Blind: Towards Attention-Aware AIED. Int J Artif Intell Educ 26, 645–659 (2016). https://doi.org/10.1007/s40593-016-0104-1","There is an inextricable link between attention and learning, yet AIED systems in 2015 are largely blind to learners’ attentional states. We argue that next-generation AIED systems should have the ability to monitor and dynamically (re)direct attention in order to optimize allocation of sparse attentional resources. We present some initial ideas towards achieving this goal, starting with a 2<U+2009>×<U+2009>2 (direction of attention × content of thoughts) organizational framework that encapsulates a range of attentional states including overt inattention, covert inattention, zone outs, tune outs, and focused, alternating, and divided attention. We then sketch out a three component attentional computing architecture consisting of: (1) devices to monitor where attention appears to be directed; (2) mechanisms for real-time attentional state diagnosis; and (3) interventions to dynamically (re)direct attention. We describe two closed-loop attention-aware AIED systems to serve as concrete renditions of these ideas. We conclude by arguing that AIED can achieve the dual goals of advancing basic research on the science of learning while simultaneously developing highly-effective AIED systems by “attending to attention.”"
"Stupid Tutoring Systems, Intelligent Humans","International Journal of Artificial Intelligence in Education","volume26","600","614","2016","Baker, R.S. Stupid Tutoring Systems, Intelligent Humans. Int J Artif Intell Educ 26, 600–614 (2016). https://doi.org/10.1007/s40593-016-0105-0","The initial vision for intelligent tutoring systems involved powerful, multi-faceted systems that would leverage rich models of students and pedagogies to create complex learning interactions. But the intelligent tutoring systems used at scale today are much simpler. In this article, I present hypotheses on the factors underlying this development, and discuss the potential of educational data mining driving human decision-making as an alternate paradigm for online learning, focusing on intelligence amplification rather than artificial intelligence."
"The Evolution of Research on Digital Education","International Journal of Artificial Intelligence in Education","volume26","544","560","2016","Dillenbourg, P. The Evolution of Research on Digital Education. Int J Artif Intell Educ 26, 544–560 (2016). https://doi.org/10.1007/s40593-016-0106-z","How does AI&EdAIED today compare to 25 years ago? This paper addresses this evolution by identifying six trends. The trends are ongoing and will influence learning technologies going forward. First, the physicality of interactions and the physical space of the learner became genuine components of digital education. The frontier between the digital and the physical has faded out. Similarly, the opposition between individual and social views on cognition has been subsumed by integrated learning scenarios, which means that AIED pays more attention today to social interactions than it did at its outset. Another trend is the processing of learners’ behavioural particles, which do not carry very many semantics when considered individually, but are predictive of knowledge states when large data sets are processed with machine learning methods. The development of probabilistic models and the integration of crowdsourcing methods has produced another trend: the design of learning environments has become less deterministic than before. The notion of learning environment evolved from a rather closed box to an open ecosystem in which multiple components are distributed over multiple platforms and where multiple stakeholders interact. Among these stakeholders, it is important to notice that teachers play a more important role than before: they interact not only at the design phase (authoring) but also in the runtime phase (orchestration). These trends are not specific to AIED; they depict the evolution of learning technologies as a whole."
"Technology Support for Discussion Based Learning: From Computer Supported Collaborative Learning to the Future of Massive Open Online Courses","International Journal of Artificial Intelligence in Education","volume26","660","678","2016","Rosé, C.P., Ferschke, O. Technology Support for Discussion Based Learning: From Computer Supported Collaborative Learning to the Future of Massive Open Online Courses. Int J Artif Intell Educ 26, 660–678 (2016). https://doi.org/10.1007/s40593-016-0107-y","This article offers a vision for technology supported collaborative and discussion-based learning at scale. It begins with historical work in the area of tutorial dialogue systems. It traces the history of that area of the field of Artificial Intelligence in Education as it has made an impact on the field of Computer-Supported Collaborative Learning through the creation of forms of dynamic support for collaborative learning, and makes an argument for the importance of advances in the field of Language Technologies for this work. In particular, this support has been enabled by an integration of text mining and conversational agents to form a novel type of micro-script support for productive discussion processes. This research from the early part of the century has paved the way for emerging technologies that support discussion-based learning at scale in Massive Open Online Courses (MOOCs). In the next 25 years, we expect to see this early, emerging work in MOOC contexts grow into ubiquitously available social learning approaches in free online learning environments like MOOCs, or what comes next in the online learning space. These ambitious social learning approaches include Problem Based Learning, Team Project Based Learning, and Collaborative Reflection. We expect to see the capability of drawing in and effectively supporting learners of all walks of life, especially impacting currently under-served learners. To that end, we describe the current exploratory efforts to deploy technology supported collaborative and discussion-based learning in MOOCs and offer a vision for work going forward into the next decade, where we envision learning communities and open collaborative work communities coming together as persistent technology supported and enhanced communities of practice."
"Evolution Is not enough: Revolutionizing Current Learning Environments to Smart Learning Environments","International Journal of Artificial Intelligence in Education","volume26","561","581","2016","Kinshuk, Chen, N., Cheng, I. et al. Evolution Is not enough: Revolutionizing Current Learning Environments to Smart Learning Environments. Int J Artif Intell Educ 26, 561–581 (2016). https://doi.org/10.1007/s40593-016-0108-x","Advances in technology in recent years have changed the learning behaviors of learners and reshaped teaching methods. This had resulted in several challenges faced by current educational systems, such as an increased focus on informal learning, a growing gap of prior knowledge among students in classrooms and a mismatch between individual career choices and the development of the work force. This paper looks at these challenges with a view towards revolutionizing current learning environments to smart learning environments and provides new suggestions for technological solutions. Furthermore, this paper argues for a transformation from the current learning environments to smart learning environments. This is to be achieved by reengineering the fundamental structure and operations of current educational systems to better integrate these new technologies with the required pedagogical shift. The future perspectives of smart learning environments are reviewed and shared, through examples of emerging innovations such as the flipped classroom, game based learning, gesture based learning, along with pedagogical shifts, such as life-long learning portfolio maintenance, team teaching, and separation of learning and competency assessment."
"Preface to the IJAIED 25th Anniversary Issue, Part 2","International Journal of Artificial Intelligence in Education","volume26","539","543","2016","Lane, H.C., McCalla, G., Looi, C. et al. Preface to the IJAIED 25th Anniversary Issue, Part 2. Int J Artif Intell Educ 26, 539–543 (2016). https://doi.org/10.1007/s40593-016-0109-9",""
"Evolution and Revolution in Artificial Intelligence in Education","International Journal of Artificial Intelligence in Education","volume26","582","599","2016","Roll, I., Wylie, R. Evolution and Revolution in Artificial Intelligence in Education. Int J Artif Intell Educ 26, 582–599 (2016). https://doi.org/10.1007/s40593-016-0110-3","The field of Artificial Intelligence in Education (AIED) has undergone significant developments over the last twenty-five years. As we reflect on our past and shape our future, we ask two main questions: What are our major strengths? And, what new opportunities lay on the horizon? We analyse 47 papers from three years in the history of the Journal of AIED (1994, 2004, and 2014) to identify the foci and typical scenarios that occupy the field of AIED. We use those results to suggest two parallel strands of research that need to take place in order to impact education in the next 25 years: One is an evolutionary process, focusing on current classroom practices, collaborating with teachers, and diversifying technologies and domains. The other is a revolutionary process where we argue for embedding our technologies within students’ everyday lives, supporting their cultures, practices, goals, and communities."
"ToTCompute: A Novel EEG-Based TimeOnTask Threshold Computation Mechanism for Engagement Modelling and Monitoring","International Journal of Artificial Intelligence in Education","volume26","821","854","2016","Ghergulescu, I., Muntean, C.H. ToTCompute: A Novel EEG-Based TimeOnTask Threshold Computation Mechanism for Engagement Modelling and Monitoring. Int J Artif Intell Educ 26, 821–854 (2016). https://doi.org/10.1007/s40593-016-0111-2","Engagement influences participation, progression and retention in game-based e-learning (GBeL). Therefore, GBeL systems should engage the players in order to support them to maximize their learning outcomes, and provide the players with adequate feedback to maintain their motivation. Innovative engagement monitoring solutions based on players’ behaviour are needed to enable engagement monitoring in a non-disturbing way, without interrupting the game-play and game flow. Furthermore, generic metrics and automatic mechanisms for their engagement monitoring and modelling are needed. One important metric that was used for engagement modelling is TimeOnTask, which represents the duration of time required by the player to complete a task. This paper proposes ToTCompute (TimeOnTask Threshold Computation), a novel mechanism that automatically computes - in a task-dependent manner - TimeOnTask threshold values after which student engagement decreases with a given percentage from his initial level of engagement (e.g., after 2 min student engagement will fall with 10 % from his initial level). In this way the mechanism enables engagement modelling at a higher granularity and further enables engagement-based adaptation in GBeL systems. ToTCompute makes use of game-playing information and EEG signals collected through an initial testing session. The results of an experimental case study have shown that ToTCompute can be used to automatically compute threshold values for the TimeOnTask generic engagement metric, which explains up to 76.2 % of the variance in engagement change. Furthermore, the results confirmed the usefulness of the mechanism as the TimeOnTask threshold value is highly task-dependent, and setting its value manually for multiple game tasks would be a laborious process."
"Evolution of an Intelligent Deductive Logic Tutor Using Data-Driven Elements","International Journal of Artificial Intelligence in Education","volume27","5","36","2017","Mostafavi, B., Barnes, T. Evolution of an Intelligent Deductive Logic Tutor Using Data-Driven Elements. Int J Artif Intell Educ 27, 5–36 (2017). https://doi.org/10.1007/s40593-016-0112-1","Deductive logic is essential to a complete understanding of computer science concepts, and is thus fundamental to computer science education. Intelligent tutoring systems with individualized instruction have been shown to increase learning gains. We seek to improve the way deductive logic is taught in computer science by developing an intelligent, data-driven logic tutor. We have augmented Deep Thought, an existing computer-based logic tutor, by adding data-driven methods, specifically; intelligent problem selection based on the student’s current proficiency, automatically generated on-demand hints, and determination of student problem solving strategies based on clustering previous students. As a result, student tutor completion (the amount of the tutor the students completed) steadily improved as data-driven methods were added to Deep Thought, allowing students to be exposed to more logic concepts. We also gained additional insights into the effects of different course work and teaching methods on tutor effectiveness."
"An Analysis of Student Model Portability","International Journal of Artificial Intelligence in Education","volume26","932","974","2016","Valdés Aguirre, B., Ramírez Uresti, J.A. & Boulay, B.d. An Analysis of Student Model Portability. Int J Artif Intell Educ 26, 932–974 (2016). https://doi.org/10.1007/s40593-016-0113-0","Sharing user information between systems is an area of interest for every field involving personalization. Recommender Systems are more advanced in this aspect than Intelligent Tutoring Systems (ITSs) and Intelligent Learning Environments (ILEs). A reason for this is that the user models of Intelligent Tutoring Systems and Intelligent Learning Environments, i.e. their student models, tend to be more heterogeneous and complex than traditional models used in Recommender Systems. To share and reuse student models we must first understand the restrictions for porting or reusing student models in new ITSs or ILEs. This paper proposes a classification of student models in terms of their portability. Portability is measured via each model’s accessibility, complexity, architecture, popularity, and description. We use this classification to analyse and then grade student models that have been published in the AIED, EDM and ITS research communities in 2013 and 2014. The classification is intended to be used by researchers both as a methodology to measure the portability of a student model and as a guide to find existing reusable models."
"Preface to Special Issue on User Modelling to Support Personalization in Enhanced Educational Settings","International Journal of Artificial Intelligence in Education","volume26","809","820","2016","Santos, O.C., Kravcik, M. & Boticario, J.G. Preface to Special Issue on User Modelling to Support Personalization in Enhanced Educational Settings. Int J Artif Intell Educ 26, 809–820 (2016). https://doi.org/10.1007/s40593-016-0114-z","Personalization approaches in learning environments aim to foster effective, active, efficient, and satisfactory learning. Suitable user modelling techniques are crucial to support these approaches in dealing with learners’ needs within realistic learning environments, which are currently cropping up in a varied range of situations. Bearing this in mind, this paper provides an overview of relevant research over the last five years in both user modelling and education, which shows an increasing interest among researchers and practitioners who are concerned with modelling users’ needs in the new and evolving educational settings that are widening the diversity of learning contexts and issues to be considered. In particular, we have identified three main areas of research: i) modelling of learners and their performance to provide engaging learning experiences, ii) designing adaptive support, and iii) building standards-based models to cope with interoperability and portability."
"Argumentation Scheme-Based Argument Generation to Support Feedback in Educational Argument Modeling Systems","International Journal of Artificial Intelligence in Education","volume27","515","533","2017","Green, N.L. Argumentation Scheme-Based Argument Generation to Support Feedback in Educational Argument Modeling Systems. Int J Artif Intell Educ 27, 515–533 (2017). https://doi.org/10.1007/s40593-016-0115-y","This paper describes an educational argument modeling system, GAIL (Genetics Argumentation Inquiry Learning). Using GAIL’s graphical interface, learners can select from possible argument content elements (hypotheses, data, etc.) displayed on the screen with which to construct argument diagrams. Unlike previous systems, GAIL uses domain-independent argumentation schemes to generate expert arguments as a knowledge source. By comparing the learner’s argument diagram to a generated argument, GAIL can provide problem-specific feedback on both the structure and meaning of the learner’s argument, e.g., that the learner’s argument contains an irrelevant premise. To generate arguments, the argumentation schemes are instantiated from causal domain models specified by lesson authors. Thus, this approach to generating expert arguments has the potential to be used in other domains. In this paper we describe use of GAIL’s Authoring Tool to create the domain model and content elements to be provided for a specific lesson, how expert arguments are generated in GAIL, and how the feedback is produced. As GAIL is a work-in-progress, the paper also describes plans for the next design iteration."
"An Educational System for Learning Search Algorithms and Automatically Assessing Student Performance","International Journal of Artificial Intelligence in Education","volume27","207","240","2017","Grivokostopoulou, F., Perikos, I. & Hatzilygeroudis, I. An Educational System for Learning Search Algorithms and Automatically Assessing Student Performance. Int J Artif Intell Educ 27, 207–240 (2017). https://doi.org/10.1007/s40593-016-0116-x","In this paper, first we present an educational system that assists students in learning and tutors in teaching search algorithms, an artificial intelligence topic. Learning is achieved through a wide range of learning activities. Algorithm visualizations demonstrate the operational functionality of algorithms according to the principles of active learning. So, a visualization process can stop and request from a student to specify the next step or explain the way that a decision was made by the algorithm. Similarly, interactive exercises assist students in learning to apply algorithms in a step-by-step interactive way. Students can apply an algorithm to an example case, specifying the algorithm’s steps interactively, with the system’s guidance and help, when necessary. Next, we present assessment approaches integrated in the system that aim to assist tutors in assessing the performance of students, reduce their marking task workload and provide immediate and meaningful feedback to students. Automatic assessment is achieved in four stages, which constitute a general assessment framework. First, the system calculates the similarity between the student’s and the correct answer using the edit distance metric. In the next stage, it identifies the type of the answer, based on an introduced answer categorization scheme related to completeness and accuracy of an answer, taking into account student carelessness too. Afterwards, the types of errors are identified, based on an introduced error categorization scheme. Finally, answer is automatically marked via an automated marker, based on its type, the edit distance and the type of errors made. To assess the learning effectiveness of the system an extended evaluation study was conducted in real class conditions. The experiment showed very encouraging results. Furthermore, to evaluate the performance of the assessment system, we compared the assessment mechanism against expert (human) tutors. A total of 400 students’ answers were assessed by three tutors and the results showed a very good agreement between the automatic assessment system and the tutors."
"A New Perspective of Negotiation-Based Dialog to Enhance Metacognitive Skills in the Context of Open Learner Models","International Journal of Artificial Intelligence in Education","volume26","1069","1115","2016","Suleman, R.M., Mizoguchi, R. & Ikeda, M. A New Perspective of Negotiation-Based Dialog to Enhance Metacognitive Skills in the Context of Open Learner Models. Int J Artif Intell Educ 26, 1069–1115 (2016). https://doi.org/10.1007/s40593-016-0118-8","Negotiation mechanism using conversational agents (chatbots) has been used in Open Learner Models (OLM) to enhance learner model accuracy and provide opportunities for learner reflection. Using chatbots that allow for natural language discussions has shown positive learning gains in students. Traditional OLMs assume a learner to be able to manage their own learning and already in an appropriate affective/behavioral state that is conducive for learning. This paper proposes a new perspective of learning that advances the state of the art in fully-negotiated OLMs by exploiting learner’s affective & behavioral states to generate engaging natural language dialogues that train them to enhance their metacognitive skills. In order to achieve this, we have developed the NDLtutor that provides a natural language interface to learners. Our system generates context-aware dialogues automatically to enhance learner participation and reflection. This paper provides details on the design and implementation of the NDLtutor and discusses two evaluation studies. The first evaluation study focuses on the dialogue management capabilities of our system and demonstrates that our dialog system works satisfactorily to realize meaningful and natural interactions for negotiation. The second evaluation study investigates the effects of our system on the self-assessment and self-reflection of the learners. The results of the evaluations show that the NDLtutor is able to produce significant improvements in the self-assessment accuracy of the learners and also provides adequate support for prompting self-reflection in learners."
"Designing Academic Writing Analytics for Civil Law Student Self-Assessment","International Journal of Artificial Intelligence in Education","volume28","1","28","2018","Knight, S., Buckingham Shum, S., Ryan, P. et al. Designing Academic Writing Analytics for Civil Law Student Self-Assessment. Int J Artif Intell Educ 28, 1–28 (2018). https://doi.org/10.1007/s40593-016-0121-0","Research into the teaching and assessment of student writing shows that many students find academic writing a challenge to learn, with legal writing no exception. Improving the availability and quality of timely formative feedback is an important aim. However, the time-consuming nature of assessing writing makes it impractical for instructors to provide rapid, detailed feedback on hundreds of draft texts which might be improved prior to submission. This paper describes the design of a natural language processing (NLP) tool to provide such support. We report progress in the development of a web application called AWA (Academic Writing Analytics), which has been piloted in a Civil Law degree. We describe: the underlying NLP platform and the participatory design process through which the law academic and analytics team tested and refined an existing rhetorical parser for the discipline; the user interface design and evaluation process; and feedback from students, which was broadly positive, but also identifies important issues to address. We discuss how our approach is positioned in relation to concerns regarding automated essay grading, and ways in which AWA might provide more actionable feedback to students. We conclude by considering how this design process addresses the challenge of making explicit to learners and educators the underlying mode of action in analytic devices such as our rhetorical parser, which we term algorithmic accountability."
"Assessing Text-Based Writing of Low-Skilled College Students","International Journal of Artificial Intelligence in Education","volume28","56","78","2018","Perin, D., Lauterbach, M. Assessing Text-Based Writing of Low-Skilled College Students. Int J Artif Intell Educ 28, 56–78 (2018). https://doi.org/10.1007/s40593-016-0122-z","The problem of poor writing skills at the postsecondary level is a large and troubling one. This study investigated the writing skills of low-skilled adults attending college developmental education courses by determining whether variables from an automated scoring system were predictive of human scores on writing quality rubrics. The human-scored measures were a holistic quality rating for a persuasive essay and an analytic quality score for a written summary. Both writing samples were based on text on psychology and sociology topics related to content taught at the introductory undergraduate level. The study is a modified replication of McNamara et al. (Written Communication, 27(1), 57–86 2010), who identified several Coh-Metrix variables from five linguistic classes that reliably predicted group membership (high versus low proficiency) using human quality scores on persuasive essays written by average-achieving college students. When discriminant analyses and ANOVAs failed to replicate the McNamara et al. (Written Communication, 27(1), 57–86 2010) findings, the current study proceeded to analyze all of the variables in the five Coh-Metrix classes. This larger analysis identified 10 variables that predicted human-scored writing proficiency. Essay and summary scores were predicted by different automated variables. Implications for instruction and future use of automated scoring to understand the writing of low-skilled adults are discussed."
"Preface for the Special Issue on AI-Supported Education in Computer Science","International Journal of Artificial Intelligence in Education","volume27","1","4","2017","Barnes, T., Boyer, K., Hsiao, S.I. et al. Preface for the Special Issue on AI-Supported Education in Computer Science. Int J Artif Intell Educ 27, 1–4 (2017). https://doi.org/10.1007/s40593-016-0123-y",""
"Computing of Learner’s Personality Traits Based on Digital Annotations","International Journal of Artificial Intelligence in Education","volume27","241","267","2017","Omheni, N., Kalboussi, A., Mazhoud, O. et al. Computing of Learner’s Personality Traits Based on Digital Annotations. Int J Artif Intell Educ 27, 241–267 (2017). https://doi.org/10.1007/s40593-016-0124-x","Researchers in education are interested in modeling of learner’s profile and adapt their learning experiences accordingly. When learners read and interact with their reading materials, they do unconscious practices like annotations which may be, a key feature of their personalities. Annotation activity requires readers to be active, to think critically and to analyze what has been drawn up, and to make explicit annotations in the margins of the text. Readers make annotation traces through underlining, highlighting, scribbling comments, summarizing, asking questions, expressing confusion or ambiguity, and evaluating the reading content. In this paper, we present a semi-automatic approach to building learners’ personality profiles based on their annotation traces yielded during an active reading session. The experimental results show the system’s efficiency to measure, with reasonable accuracy, the scores of a learner’s conscientiousness and neurotics traits."
"Designing Crowdcritique Systems for Formative Feedback","International Journal of Artificial Intelligence in Education","volume27","623","663","2017","Easterday, M.W., Rees Lewis, D. & Gerber, E.M. Designing Crowdcritique Systems for Formative Feedback. Int J Artif Intell Educ 27, 623–663 (2017). https://doi.org/10.1007/s40593-016-0125-9","Intelligent tutors based on expert systems often struggle to provide formative feedback on complex, ill-defined problems where answers are unknown. Hybrid crowdsourcing systems that combine the intelligence of multiple novices in face-to-face settings might provide an alternate approach for providing intelligent formative feedback. The purpose of this study was to develop empirically grounded design principles for crowdcritique systems that provide intelligent formative feedback on complex, ill-defined problems. In this design research project, we iteratively developed and tested a crowdcritique system through 3 studies of 43 novice problem solvers in 3 formal and informal learning environments. We collected observations, interviews, and surveys and used a grounded theory approach to develop and test socio-technical design principles for crowdcritique systems. The project found that to provide formative feedback on ill-defined problems, crowdcritique systems should provide a combination of technical features including: quick invite tools; formative framing; a public, near-synchronous social media interface; critique scaffolds; “like” system; community hashtags; analysis tools and “to do” lists; along with social practices including: prep/write-first/write-last script and critique training. Such a system creates a dual-channel conversation that increases the volume of quality critique by grounding comments, scaffolding and recording critique, and reducing production blocking. Such a design provides the benefits of both face-to-face critique and computer-support in both formal and informal learning environments while reducing the orchestration burden on instructors."
"Developing Emotion-Aware, Advanced Learning Technologies: A Taxonomy of Approaches and Features","International Journal of Artificial Intelligence in Education","volume27","268","297","2017","Harley, J.M., Lajoie, S.P., Frasson, C. et al. Developing Emotion-Aware, Advanced Learning Technologies: A Taxonomy of Approaches and Features. Int J Artif Intell Educ 27, 268–297 (2017). https://doi.org/10.1007/s40593-016-0126-8","A growing body of work on intelligent tutoring systems, affective computing, and artificial intelligence in education is exploring creative, technology-driven approaches to enhance learners’ experience of adaptive, positively-valenced emotions while interacting with advanced learning technologies. Despite this, there has been no published work to date that captures this topic’s breadth. We took up this grand challenge by integrating related empirical studies and existing conceptual work and proposing a theoretically-guided taxonomy for the development and improvement of emotion-aware systems. In particular, multiple strategies system developers may use to help learners experience positive emotions are mapped out, including those that require different amounts and types of information about the user, as well as when this information is required. Examples from the literature are provided to illustrate how different emotion-aware system approaches can be combined to take advantage of different types of data, both prior to and during the learner-system interaction. High-level system features that emotion-aware systems can tailor to learners in order to elicit positive emotions are also described and exemplified. Theoretically, the taxonomy is primarily informed by the control-value theory of achievement emotions (Pekrun 2006, 2011) and its assumptions about the relationship between distal and proximal antecedents and the elicitation and regulation of emotion. The taxonomy expands upon a dichotomy of emotion-aware systems proposed by D’Mello and Graesser (2015) and is intended to guide the design of emotion-aware systems that can foster positive emotions during learner-system interactions through the use of varied approaches, data sources, and design features."
"Comprehension and Writing Strategy Training Improves Performance on Content-Specific Source-Based Writing Tasks","International Journal of Artificial Intelligence in Education","volume28","106","137","2018","Weston-Sementelli, J.L., Allen, L.K. & McNamara, D.S. Comprehension and Writing Strategy Training Improves Performance on Content-Specific Source-Based Writing Tasks. Int J Artif Intell Educ 28, 106–137 (2018). https://doi.org/10.1007/s40593-016-0127-7","Source-based essays are evaluated both on the quality of the writing and the content appropriate interpretation and use of source material. Hence, composing a high-quality source-based essay (an essay written based on source material) relies on skills related to both reading (the sources) and writing (the essay) skills. As such, source-based writing must involve language comprehension and production processes. The purpose of the current study is to examine the impact of reading, writing, and blended (i.e., reading and writing) strategy training on students’ performance on a content-specific source-based essay writing task. In contrast to general source-based writing tasks, content-specific source-based writing tasks are tasks wherein writers are provided the source material on which to base their essays. Undergraduate students (n = 175) were provided with strategy instruction and practice in the context of two intelligent tutoring systems, Writing Pal and Interactive Strategy Training for Active Reading and Thinking (iSTART). Results indicated that participants in the blended strategy training condition produced higher quality source-based essays than participants in the reading comprehension-only, writing-only, or control condition, with no differences observed between the latter three conditions. Further, the benefits of this blended strategy instruction remained significant regardless of prior reading and writing skills, or time on task."
"Wise Crowd Content Assessment and Educational Rubrics","International Journal of Artificial Intelligence in Education","volume28","29","55","2018","Passonneau, R.J., Poddar, A., Gite, G. et al. Wise Crowd Content Assessment and Educational Rubrics. Int J Artif Intell Educ 28, 29–55 (2018). https://doi.org/10.1007/s40593-016-0128-6","Development of reliable rubrics for educational intervention studies that address reading and writing skills is labor-intensive, and could benefit from an automated approach. We compare a main ideas rubric used in a successful writing intervention study to a highly reliable wise-crowd content assessment method developed to evaluate machine-generated summaries. The ideas in the educational rubric were extracted from a source text that students were asked to summarize. The wise-crowd content assessment model is derived from summaries written by an independent group of proficient students who read the same source text, and followed the same instructions to write their summaries. The resulting content model includes a ranking over the derived content units. All main ideas in the rubric appear prominently in the wise-crowd content model. We present two methods that automate the content assessment. Scores based on the wise-crowd content assessment, both manual and automated, have high correlations with the main ideas rubric. The automated content assessment methods have several advantages over related methods, including high correlations with corresponding manual scores, a need for only half a dozen models instead of hundreds, and interpretable scores that independently assess content quality and coverage."
"Role of Working Memory and Strategy-Use in Feedback Effects on children’s Progression in Analogy Solving:an Explanatory Item Response Theory Account","International Journal of Artificial Intelligence in Education","volume27","393","418","2017","Stevenson, C.E. Role of Working Memory and Strategy-Use in Feedback Effects on children’s Progression in Analogy Solving:an Explanatory Item Response Theory Account. Int J Artif Intell Educ 27, 393–418 (2017). https://doi.org/10.1007/s40593-016-0129-5","This study contrasted the effects of tutoring, multiple try and no feedback on children’s progression in analogy solving and examined individual differences herein. Feedback that includes additional hints or explanations leads to the greatest learning gains in adults. However, children process feedback differently from adults and effective feedback likely differs between learners with different characteristics or at different stages in the learning process. In this paper multilevel explanatory item response theory models were used to examine individual differences in feedback effects in children’s performance on a computerized pretest-training-posttest assessment of analogical reasoning. The role of working memory and ability level, based on initial strategy-use, were examined in a sample of 999 5–10 year-old children who received either tutoring feedback, multiple tries or no feedback during the training sessions. The results indicate that tutoring feedback leads to the greatest performance gains; however, this was moderated by working memory and ability level. Children who initially used less advanced strategies benefited more from each type of feedback than children who used advanced strategies at pretest. Higher working memory scores were linked to greater benefit from tutoring feedback or no feedback, whereas learning gains in the multiple try condition were not related to working memory. The findings of this study contribute to the growing literature on how to personalize feedback to the learner’s instructional-needs."
"The Impacts of Domain-General vs. Domain-Specific Diagramming Tools on Writing","International Journal of Artificial Intelligence in Education","volume27","671","693","2017","Barstow, B., Fazio, L., Lippman, J. et al. The Impacts of Domain-General vs. Domain-Specific Diagramming Tools on Writing. Int J Artif Intell Educ 27, 671–693 (2017). https://doi.org/10.1007/s40593-016-0130-z","Argument diagramming is the process of spatially representing an argument by its component parts and their relationships. A growing body of evidence supports the use of argument diagramming to aid student learning and writing within disciplines including science education. However, most of these studies have focused on basic contrasts between diagramming and no diagramming. The purpose of this study was to learn how different diagramming frameworks affect the benefits afforded by argument diagramming. Three groups of undergraduate students in psychology research methods lab courses were given either no diagramming support, support with a domain-general framework, or support with a domain-specific framework to help them write a research paper introduction. Students given any diagramming support included more relevant citations and considered opposing citations in their papers. Students using the domain-specific framework wrote more about the scientific validity of cited studies than the other two groups, whereas students using the domain-general framework trended towards included more supporting citations."
"Applying a Framework for Student Modeling in Exploratory Learning Environments: Comparing Data Representation Granularity to Handle Environment Complexity","International Journal of Artificial Intelligence in Education","volume27","320","352","2017","Fratamico, L., Conati, C., Kardan, S. et al. Applying a Framework for Student Modeling in Exploratory Learning Environments: Comparing Data Representation Granularity to Handle Environment Complexity. Int J Artif Intell Educ 27, 320–352 (2017). https://doi.org/10.1007/s40593-016-0131-y","Interactive simulations can facilitate inquiry learning. However, similarly to other Exploratory Learning Environments, students may not always learn effectively in these unstructured environments. Thus, providing adaptive support has great potential to help improve student learning with these rich activities. Providing adaptive support requires a student model that can both evaluate learning as well inform relevant feedback. Building such a model for interactive simulations is especially challenging because the exploratory nature of the interaction makes it hard to know a priori which behaviors are conducive to learning. To address this problem, in this paper we leverage the student modeling framework proposed in (Kardan and Conati, 2011) to specifically address the challenge of modeling students in interactive simulations. The framework has already been successfully applied to build a student model and to give adaptive interventions for an interactive simulation for constraint satisfaction. We seek to investigate the generality of the framework by building student models for a more complex simulation on electric circuits called Circuit Construction Kit (CCK). We evaluate alternative representations of logged interaction data with CCK, capturing different amounts of granularity and feature engineering. We then apply the student modeling framework proposed in (Kardan and Conati, 2011) to group students based on their interaction behaviors, map these behaviors into learning outcomes and leverage the resulting clusters to classify new learners. Data collected from 100 college students working with the CCK simulation indicates that the proposed framework is able to successfully classify students in groups of high and low learners and identify patterns of productive behaviors that are common across representations that can inform real-time feedback. In addition to presenting these results, we discuss trade-offs between levels of granularity and feature engineering in the tested interaction representations in terms of their ability to evaluate learning, classify students, and inform feedback."
"Automated Assessment of the Quality of Peer Reviews using Natural Language Processing Techniques","International Journal of Artificial Intelligence in Education","volume27","534","581","2017","Ramachandran, L., Gehringer, E.F. & Yadav, R.K. Automated Assessment of the Quality of Peer Reviews using Natural Language Processing Techniques. Int J Artif Intell Educ 27, 534–581 (2017). https://doi.org/10.1007/s40593-016-0132-x","A review is textual feedback provided by a reviewer to the author of a submitted version. Peer reviews are used in academic publishing and in education to assess student work. While reviews are important to e-commerce sites like Amazon and e-bay, which use them to assess the quality of products and services, our work focuses on academic reviewing. We seek to help reviewers improve the quality of their reviews. One way to measure review quality is through metareview or review of reviews. We develop an automated metareview software that provides rapid feedback to reviewers on their assessment of authors’ submissions. To measure review quality, we employ metrics such as: review content type, review relevance, review’s coverage of a submission, review tone, review volume and review plagiarism (from the submission or from other reviews). We use natural language processing and machine-learning techniques to calculate these metrics. We summarize results from experiments to evaluate our review quality metrics: review content, relevance and coverage, and a study to analyze user perceptions of importance and usefulness of these metrics. Our approaches were evaluated on data from Expertiza and the Scaffolded Writing and Rewriting in the Discipline (SWoRD) project, which are two collaborative web-based learning applications."
"Designing Grounded Feedback: Criteria for Using Linked Representations to Support Learning of Abstract Symbols","International Journal of Artificial Intelligence in Education","volume27","448","474","2017","Wiese, E.S., Koedinger, K.R. Designing Grounded Feedback: Criteria for Using Linked Representations to Support Learning of Abstract Symbols. Int J Artif Intell Educ 27, 448–474 (2017). https://doi.org/10.1007/s40593-016-0133-9","This paper proposes grounded feedback as a way to provide implicit verification when students are working with a novel representation. In grounded feedback, students’ responses are in the target, to-be-learned representation, and those responses are reflected in a more-accessible linked representation that is intrinsic to the domain. By examining the accessible feedback representation, students can infer if their work with the novel representation is correct. This paper presents the criteria for grounded feedback, provides examples of systems that implement grounded feedback, contrasts grounded feedback with similar feedback types, and discusses the evidence for grounded feedback’s effectiveness. Controlled experiments with random assignment that compare grounded feedback to other approaches are limited in number and scope (i.e., comparisons to explicit verification with and without text hints, linked representations, and no feedback). The two experiments we found with full implementation of grounded feedback and a sample size larger than 20 found robust learning benefits of grounded feedback over explicit verification feedback. These results are promising and indicate that grounded feedback warrants further investigation."
"Do Knowledge-Component Models Need to Incorporate Representational Competencies?","International Journal of Artificial Intelligence in Education","volume27","298","319","2017","Rau, M.A. Do Knowledge-Component Models Need to Incorporate Representational Competencies?. Int J Artif Intell Educ 27, 298–319 (2017). https://doi.org/10.1007/s40593-016-0134-8","Traditional knowledge-component models describe students’ content knowledge (e.g., their ability to carry out problem-solving procedures or their ability to reason about a concept). In many STEM domains, instruction uses multiple visual representations such as graphs, figures, and diagrams. The use of visual representations implies a “representation dilemma”: students learn new content from visual representations they may not yet understand at the same time as they learn about visual representations that show content they do not yet understand. Therefore, students’ learning of content knowledge and of representational competencies (i.e., knowledge about representations) is invariably intertwined. Consequently, instruction may need to adapt not only to students’ acquisition of content knowledge but also to their acquisition of representational competencies. This claim corresponds to the hypothesis that knowledge-component models that describe content knowledge and representational competencies should be more accurate than knowledge-component models that describe only content knowledge. Yet, this hypothesis has not yet been tested. The work in this article tests this hypothesis by comparing knowledge-component models that describe representational competencies and content knowledge to knowledgecomponent models that describe only content knowledge. Analysis of log data from two experiments on chemistry learning with overall 203 undergraduate students suggests that including representational competencies into knowledge-component models increases model fit if the representational competencies are difficult. This finding suggests that students can learn abstract content knowledge only if they have a prerequisite level of representational competencies, and that educational technologies should use adaptive knowledge-component models that capture representational competencies the student has not yet mastered."
"New Directions in Formative Feedback in Interactive Learning Environments","International Journal of Artificial Intelligence in Education","volume27","385","392","2017","Goldin, I., Narciss, S., Foltz, P. et al. New Directions in Formative Feedback in Interactive Learning Environments. Int J Artif Intell Educ 27, 385–392 (2017). https://doi.org/10.1007/s40593-016-0135-7","Formative feedback is well known as a key factor in influencing learning. Modern interactive learning environments provide a broad range of ways to provide feedback to students as well as new tools to understand feedback and its relation to various learning outcomes. This issue focuses on the role of formative feedback through a lens of how technologies both support student learning and enhance our understanding of the mechanisms of feedback. The papers in the issue span a variety of feedback strategies, instructional domains, AI techniques, and educational use cases in order to improve and understand formative feedback in interactive learning environments. The issue encompasses three primary themes critical to understanding formative feedback: 1) the role of human information processing and individual learner characteristics for feedback efficiency, 2) how to deliver meaningful feedback to learners in domains of study where student work is difficult to assess, and 3) how human feedback sources (e.g., peer students) can be supported by user interfaces and technology-generated feedback."
"Iterative Design and Classroom Evaluation of Automated Formative Feedback for Improving Peer Feedback Localization","International Journal of Artificial Intelligence in Education","volume27","582","622","2017","Nguyen, H., Xiong, W. & Litman, D. Iterative Design and Classroom Evaluation of Automated Formative Feedback for Improving Peer Feedback Localization. Int J Artif Intell Educ 27, 582–622 (2017). https://doi.org/10.1007/s40593-016-0136-6","A peer-review system that automatically evaluates and provides formative feedback on free-text feedback comments of students was iteratively designed and evaluated in college and high-school classrooms. Classroom assignments required students to write paper drafts and submit them to a peer-review system. When student peers later submitted feedback comments on the papers to the system, Natural Language Processing was used to automatically evaluate peer feedback quality with respect to localization (i.e., pinpointing the source of the comment in the paper being reviewed). These evaluations in turn triggered immediate formative feedback by the system, which was designed to increase peer feedback localization whenever a feedback submission was predicted to have a ratio of localized comments less than a threshold. System feedback was dynamically generated based on the results of localization prediction. Reviewers could choose to either revise their feedback comments to address the system’s feedback or could ignore the feedback. Our analysis of data from system logs demonstrates that our peer feedback localization prediction model triggered the formative feedback with high precision, particularly when peer feedback comments were written by college students. Our findings also show that although students often incorrectly disagree with the system’s feedback, when they do revise their peer feedback comments, the system feedback was successful in increasing peer feedback localization (although the sample size was low). Finally, while most peer comments were revised immediately after the system feedback, the desired revision behavior also occurred further after such system feedback."
"Assessing Whether Students Seek Constructive Criticism: The Design of an Automated Feedback System for a Graphic Design Task","International Journal of Artificial Intelligence in Education","volume27","419","447","2017","Cutumisu, M., Blair, K.P., Chin, D.B. et al. Assessing Whether Students Seek Constructive Criticism: The Design of an Automated Feedback System for a Graphic Design Task. Int J Artif Intell Educ 27, 419–447 (2017). https://doi.org/10.1007/s40593-016-0137-5","We introduce a choice-based assessment strategy that measures students’ choices to seek constructive feedback and to revise their work. We present the feedback system of a game we designed to assess whether students choose positive or negative feedback and choose to revise their posters in the context of a poster design task, where they learn graphic design principles from feedback. We then describe an empirical study that sampled one hundred and six students from a US middle school to evaluate the feedback system. We make the following contributions: (1) describe the design and implementation of a novel feedback system embedded in an assessment game, Posterlet, (2) outline an approach to analyze graphic design principles automatically to provide contextual feedback in a novel poster design domain, (3) show that choices to seek negative feedback and to revise correlate with in-game performance, and most importantly, (4) show that choices correlate with in-school achievement: the choice to revise correlated with both in-school performance measures (Science and Mathematics grades), while the choice to seek negative feedback correlated with students’ prior standardized scores in Mathematics."
"Different Approaches to Assessing the Quality of Explanations Following a Multiple-Document Inquiry Activity in Science","International Journal of Artificial Intelligence in Education","volume27","758","790","2017","Wiley, J., Hastings, P., Blaum, D. et al. Different Approaches to Assessing the Quality of Explanations Following a Multiple-Document Inquiry Activity in Science. Int J Artif Intell Educ 27, 758–790 (2017). https://doi.org/10.1007/s40593-017-0138-z","This article describes several approaches to assessing student understanding using written explanations that students generate as part of a multiple-document inquiry activity on a scientific topic (global warming). The current work attempts to capture the causal structure of student explanations as a way to detect the quality of the students’ mental models and understanding of the topic by combining approaches from Cognitive Science and Artificial Intelligence, and applying them to Education. First, several attributes of the explanations are explored by hand coding and leveraging existing technologies (LSA and Coh-Metrix). Then, we describe an approach for inferring the quality of the explanations using a novel, two-phase machine-learning approach for detecting causal relations and the causal chains that are present within student essays. The results demonstrate the benefits of using a machine-learning approach for detecting content, but also highlight the promise of hybrid methods that combine ML, LSA and Coh-Metrix approaches for detecting student understanding. Opportunities to use automated approaches as part of Intelligent Tutoring Systems that provide feedback toward improving student explanations and understanding are discussed."
"Assistance and Feedback Mechanism in an Intelligent Tutoring System for Teaching Conversion of Natural Language into Logic","International Journal of Artificial Intelligence in Education","volume27","475","514","2017","Perikos, I., Grivokostopoulou, F. & Hatzilygeroudis, I. Assistance and Feedback Mechanism in an Intelligent Tutoring System for Teaching Conversion of Natural Language into Logic. Int J Artif Intell Educ 27, 475–514 (2017). https://doi.org/10.1007/s40593-017-0139-y","Logic as a knowledge representation and reasoning language is a fundamental topic of an Artificial Intelligence (AI) course and includes a number of sub-topics. One of them, which brings difficulties to students to deal with, is converting natural language (NL) sentences into first-order logic (FOL) formulas. To assist students to overcome those difficulties, we developed the NLtoFOL system and equipped it with a strong assistance and feedback mechanism. In this work, first, we present that feedback mechanism. The mechanism can provide assistance before an answer is submitted, if requested, but mainly it provides assistance after an answer is submitted. To that end, it characterizes the answer in terms of completeness and accuracy to determine the level of incorrectness, based on an answer categorization scheme, introduced in this paper. The automatically generated natural language feedback sequences grow from general to specific and can include statements on a student’s metacognitive state. Feedback is provided as natural language sentences automatically generated through a template-based natural language generation mechanism. Second, we present an extensive evaluation of the effectiveness of the assistance and feedback mechanism on students’ learning. The evaluation of feedback with students showed that full feedback sequences lead to greater learning gains than sequences consisting of only flag feedback and bottom-out hints (n<U+2009>=<U+2009>226), and that generic, template-based feedback sequences are comparable to the utility of problem-specific hints generated by human tutors (n<U+2009>=<U+2009>120)."
"Reflective Writing About the Utility Value of Science as a Tool for Increasing STEM Motivation and Retention – Can AI Help Scale Up?","International Journal of Artificial Intelligence in Education","volume27","791","818","2017","Beigman Klebanov, B., Burstein, J., Harackiewicz, J.M. et al. Reflective Writing About the Utility Value of Science as a Tool for Increasing STEM Motivation and Retention – Can AI Help Scale Up?. Int J Artif Intell Educ 27, 791–818 (2017). https://doi.org/10.1007/s40593-017-0141-4","The integration of subject matter learning with reading and writing skills takes place in multiple ways. Students learn to read, interpret, and write texts in the discipline-relevant genres. However, writing can be used not only for the purposes of practice in professional communication, but also as an opportunity to reflect on the learned material. In this paper, we address a writing intervention – Utility Value (UV) intervention – that has been shown to be effective for promoting interest and retention in STEM subjects in laboratory studies and field experiments. We conduct a detailed investigation into the potential of natural language processing technology to support evaluation of such writing at scale: We devise a set of features that characterize UV writing across different genres, present common themes, and evaluate UV scoring models using essays on known and new biology topics. The automated UV scoring results are, we believe, promising, especially for the personal essay genre."
"Automated Assessment of Non-Native Learner Essays: Investigating the Role of Linguistic Features","International Journal of Artificial Intelligence in Education","volume28","79","105","2018","Vajjala, S. Automated Assessment of Non-Native Learner Essays: Investigating the Role of Linguistic Features. Int J Artif Intell Educ 28, 79–105 (2018). https://doi.org/10.1007/s40593-017-0142-3","Automatic essay scoring (AES) refers to the process of scoring free text responses to given prompts, considering human grader scores as the gold standard. Writing such essays is an essential component of many language and aptitude exams. Hence, AES became an active and established area of research, and there are many proprietary systems used in real life applications today. However, not much is known about which specific linguistic features are useful for prediction and how much of this is consistent across datasets. This article addresses that by exploring the role of various linguistic features in automatic essay scoring using two publicly available datasets of non-native English essays written in test taking scenarios. The linguistic properties are modeled by encoding lexical, syntactic, discourse and error types of learner language in the feature set. Predictive models are then developed using these features on both datasets and the most predictive features are compared. While the results show that the feature set used results in good predictive models with both datasets, the question ”what are the most predictive features?” has a different answer for each dataset."
"Assessing Students’ Use of Evidence and Organization in Response-to-Text Writing: Using Natural Language Processing for Rubric-Based Automated Scoring","International Journal of Artificial Intelligence in Education","volume27","694","728","2017","Rahimi, Z., Litman, D., Correnti, R. et al. Assessing Students’ Use of Evidence and Organization in Response-to-Text Writing: Using Natural Language Processing for Rubric-Based Automated Scoring. Int J Artif Intell Educ 27, 694–728 (2017). https://doi.org/10.1007/s40593-017-0143-2","This paper presents an investigation of score prediction based on natural language processing for two targeted constructs within analytic text-based writing: 1) students’ effective use of evidence and, 2) their organization of ideas and evidence in support of their claim. With the long-term goal of producing feedback for students and teachers, we designed a task-dependent model, for each dimension, that aligns with the scoring rubric and makes use of the source material. We believe the model will be meaningful and easy to interpret given the writing task. We used two datasets of essays written by students in grades 5–6 and 6–8. Our experimental results show that our task-dependent model (consistent with the rubric) performs as well as if not outperforms competitive baselines. We also show the potential generalizability of the rubric-based model by performing cross-corpus experiments. Finally, we show that the predictive utility of different feature groups in our rubric-based modeling approach is related to how much each feature group covers a rubric’s criteria."
"AI in Informal Science Education: Bringing Turing Back to Life to Perform the Turing Test","International Journal of Artificial Intelligence in Education","volume27","353","384","2017","Gonzalez, A.J., Hollister, J.R., DeMara, R.F. et al. AI in Informal Science Education: Bringing Turing Back to Life to Perform the Turing Test. Int J Artif Intell Educ 27, 353–384 (2017). https://doi.org/10.1007/s40593-017-0144-1","This paper describes an interactive museum exhibit featuring an avatar of Alan Turing that informs museum visitors about artificial intelligence and Turing’s seminal Turing Test for machine intelligence. The objective of the exhibit is to engage and motivate visiting children in the hope of sparking an interest in them about computer science and artificial intelligence, and cause them to consider pursuing future studies and/or careers in these fields. The exhibit interacts with the visitors, allowing them to participate in a simplified version of Turing’s test that is brief and informal to suit the limitations of a five-minute exhibit. In this exhibit, the visitor (targeted towards middle school age children) invokes an avatar of his/her own choice, and acts to endow it with human-like qualities (voice, brain, eyesight and hearing). Then, the visitor engages the avatar in a (brief) question-and-answer session to determine whether the visitor thinks that he/she is interacting with a real human on a video conference or with an avatar. We consider this interaction to be an extension of the original Turing Test because, unlike Turing’s original that used text via a teletype, this version features a graphical embodiment of an agent with which one can converse in spoken natural language. This extension serves to make passing the Turing Test more difficult, as now the avatar must not only communicate like a human, but also look, sound and act the part. It also makes the exhibit visual, dynamic and interesting to the visitors. Evaluations were performed with museum visitors, both in backrooms with prototypes as well as on the museum floor with the final version. The formative and summative evaluations performed indicated overall success in engaging the museum visitors and increasing their interest in computer science. More specifically, the formative testing, mostly done in quiet back rooms with selected test subjects, indicated that on the important questions about enjoyment of exhibit and increased interest in computer science by the test subjects, their self-reported Likert scale responses (1 being negative and 5 being positive) increased from 3.16 in the first evaluation to 4.38 in the third one for increased interest in CS. Likewise for the question about exhibit enjoyment (from 3.92 to 4.56). The summative evaluation, done through unobtrusive observation of exhibit use on museum floor, indicated that almost 74% of the parties that initiated the exhibit were either highly or moderately engaged by the exhibit. However, there was one major negative finding, namely the overly long duration of the exhibit, which may have caused premature abandonment of the exhibit in several cases during the summative evaluation. These tests and their results are presented and discussed in detail in this paper. The exhibit has been on permanent display at the Orlando (FL) Science Center since June 2014 and has received a strongly positive response from visitors since that time."
"Designing Adaptive Instruction for Teams: a Meta-Analysis","International Journal of Artificial Intelligence in Education","volume28","225","264","2018","Sottilare, R.A., Shawn Burke, C., Salas, E. et al. Designing Adaptive Instruction for Teams: a Meta-Analysis. Int J Artif Intell Educ 28, 225–264 (2018). https://doi.org/10.1007/s40593-017-0146-z","The goal of this research was the development of a practical architecture for the computer-based tutoring of teams. This article examines the relationship of team behaviors as antecedents to successful team performance and learning during adaptive instruction guided by Intelligent Tutoring Systems (ITSs). Adaptive instruction is a training or educational experience tailored by artificially-intelligent, computer-based tutors with the goal of optimizing learner outcomes (e.g., knowledge and skill acquisition, performance, enhanced retention, accelerated learning, or transfer of skills from instructional environments to work environments). The core contribution of this research was the identification of behavioral markers associated with the antecedents of team performance and learning thus enabling the development and refinement of teamwork models in ITS architectures. Teamwork focuses on the coordination, cooperation, and communication among individuals to achieve a shared goal. For ITSs to optimally tailor team instruction, tutors must have key insights about both the team and the learners on that team. To aid the modeling of teams, we examined the literature to evaluate the relationship of teamwork behaviors (e.g., communication, cooperation, coordination, cognition, leadership/coaching, and conflict) with team outcomes (learning, performance, satisfaction, and viability) as part of a large-scale meta-analysis of the ITS, team training, and team performance literature. While ITSs have been used infrequently to instruct teams, the goal of this meta-analysis make team tutoring more ubiquitous by: identifying significant relationships between team behaviors and effective performance and learning outcomes; developing instructional guidelines for team tutoring based on these relationships; and applying these team tutoring guidelines to the Generalized Intelligent Framework for Tutoring (GIFT), an open source architecture for authoring, delivering, managing, and evaluating adaptive instructional tools and methods. In doing this, we have designed a domain-independent framework for the adaptive instruction of teams."
"Shared Mental Models in Support of Adaptive Instruction for Teams Using the GIFT Tutoring Architecture","International Journal of Artificial Intelligence in Education","volume28","265","285","2018","Fletcher, J.D., Sottilare, R.A. Shared Mental Models in Support of Adaptive Instruction for Teams Using the GIFT Tutoring Architecture. Int J Artif Intell Educ 28, 265–285 (2018). https://doi.org/10.1007/s40593-017-0147-y","Teams and teamwork are ubiquitous in military and civilian organizations. Their importance to organizational success cannot be overstated. This article describes the relationship and effect of three concepts: Intelligent Tutoring Systems (ITSs), shared mental models, and teamwork. The nexus between these concepts is examined to determine its capability to support adaptive instruction of teams, defined here as collectives of interdependent individuals who must communicate and interact with each other in order to perform assigned tasks and missions. An assumption underlying this examination is that augmenting the mental modeling processes of ITS with the mental models shared by members of interdependent teams will allow the considerable and increasingly research-established capabilities of intelligent tutoring of individuals to be applied in training teams. Specifically, we reviewed the learning and performance literature to identify how shared mental models of cognition could be used to enhance the adaptive instruction of teams. Our goal is to develop a methodology to enhance training and educational options for institutions that provide adaptive team instruction at the point-of-need. Toward this end, we discuss the adaptation of the Generalized Intelligent Framework for Tutoring (GIFT), an open source tutoring architecture, to accommodate team models and states. While this article makes a first step toward defining a process for team tutoring, challenges remain. Team tutors must have the ability to manage uncertainty and the dynamic nature of team interaction and communication in order to make effective and timely decisions that optimize team and team member performance."
"Ensemble Learning for Estimating Individualized Treatment Effects in Student Success Studies","International Journal of Artificial Intelligence in Education","volume28","315","335","2018","Beemer, J., Spoon, K., He, L. et al. Ensemble Learning for Estimating Individualized Treatment Effects in Student Success Studies. Int J Artif Intell Educ 28, 315–335 (2018). https://doi.org/10.1007/s40593-017-0148-x","Student success efficacy studies are aimed at assessing instructional practices and learning environments by evaluating the success of and characterizing student subgroups that may benefit from such modalities. We propose an ensemble learning approach to perform these analytics tasks with specific focus on estimating individualized treatment effects (ITE). ITE are a measure from the personalized medicine literature that can, for each student, quantify the impact of the intervention strategy on student performance, even though the given student either did or did not experience this intervention (i.e., is either in the treatment group or in the control group). We illustrate our learning analytics methods in the study of a supplemental instruction component for a large enrollment introductory statistics course recognized as a curriculum bottleneck at San Diego State University. As part of this application, we show how the ensemble estimate of the ITE may be used to assess the pedagogical reform (supplemental instruction), advise students into supplemental instruction at the beginning of the course, and quantify the impact of the supplemental instruction component on at-risk subgroups."
"Special Issue on the Generalized Intelligent Framework for Tutoring (GIFT): Creating a Stable and Flexible Platform for Innovations in AIED Research","International Journal of Artificial Intelligence in Education","volume28","139","151","2018","Sottilare, R.A., Baker, R.S., Graesser, A.C. et al. Special Issue on the Generalized Intelligent Framework for Tutoring (GIFT): Creating a Stable and Flexible Platform for Innovations in AIED Research. Int J Artif Intell Educ 28, 139–151 (2018). https://doi.org/10.1007/s40593-017-0149-9","The Generalized Intelligent Framework for Tutoring (GIFT) is a research prototype with three general goals associated with its functions and components: 1) lower the skills and time required to author Intelligent Tutoring Systems (ITSs) in a variety of task domains; 2) provide effective adaptive instruction tailored to the needs of each individual learner or team of learners; and 3) provide tools and methods to evaluate the effectiveness of ITSs and support research to continuously improve instructional best practices. This special issue focuses primarily on the third goal, GIFT as a research testbed. A discussion thread covers each article within this special issue and discusses its actual and potential impact on GIFT as a research tool for AIED. Our primary motivation was to introduce the AIED community to GIFT not just as a research tool, but as an extension of familiar challenges taken on previously by AIED scientists and practitioners. This preface provides a high level overview of the GIFT functions (authoring, instructional delivery and management, and experimentation) and presents its primary design principles. To learn more about GIFT, freely access the software, documentation, and associated technical papers visit www.GIFTtutoring.org."
"Design Guidelines and Empirical Case Study for Scaling Authentic Inquiry-based Science Learning via Open Online Courses and Interactive Biology Cloud Labs","International Journal of Artificial Intelligence in Education","volume28","478","507","2018","Hossain, Z., Bumbacher, E., Brauneis, A. et al. Design Guidelines and Empirical Case Study for Scaling Authentic Inquiry-based Science Learning via Open Online Courses and Interactive Biology Cloud Labs. Int J Artif Intell Educ 28, 478–507 (2018). https://doi.org/10.1007/s40593-017-0150-3","The Next Generation Science Standards (NGSS) and other national frameworks are calling for much more sophisticated approaches to STEM education, centered around the integration of complex experimentation (including real labs, not just simulations), data collection and analysis, modeling, and data-driven argumentation, i.e., students can behave like real scientists. How to implement such complex approaches in scalable ways is an unsolved challenge - both for presential and distance education. Here we report on the iterative design and large-scale deployment of an open online course with a “biology cloud experimentation lab” (using living cells) that engaged remote learners (> 300 students) in the scientific practices of experimentation, modeling and data analysis to investigate the phototaxis of a microorganism. We demonstrate (1) the robustness and scalability of the cloud lab technology (> 2,300 experiments run), (2) the design principles and synergistic integration of multiple UI and learning activities and suitable data formats to facilitate NGSS-aligned science activities, and (3) design features that leverages the natural variability of real biology experiments to instigate authentic inquiry. This platform and course content are now suited for large-scale adaptation in formal K-16 education; and we provide recommendations for inquiry-based science learning in general."
"Creating a Team Tutor Using GIFT","International Journal of Artificial Intelligence in Education","volume28","286","313","2018","Gilbert, S.B., Slavina, A., Dorneich, M.C. et al. Creating a Team Tutor Using GIFT. Int J Artif Intell Educ 28, 286–313 (2018). https://doi.org/10.1007/s40593-017-0151-2","With the movement in education towards collaborative learning, it is becoming more important that learners be able to work together in groups and teams. Intelligent tutoring systems (ITSs) have been used successfully to teach individuals, but so far only a few ITSs have been used for the purpose of training teams. This is due to the difficulty of creating such systems. An ITS for teams must be able to assess complex interactions between team members (team skills) as well as the way they interact with the system itself (task skills). Assessing team skills can be difficult because they contain social components such as communication and coordination that are not readily quantifiable. This article addresses these difficulties by developing a framework to guide the authoring process for team tutors. The framework is demonstrated using a case study about a particular team tutor that was developed using a military surveillance scenario for teams of two. The Generalized Intelligent Framework for Tutoring (GIFT) software provided the team tutoring infrastructure for this task. A new software architecture required to support the team tutor is described. This theoretical framework and the lessons learned from its implementation offer conceptual scaffolding for future authors of ITSs."
"Detecting and Addressing Frustration in a Serious Game for Military Training","International Journal of Artificial Intelligence in Education","volume28","152","193","2018","DeFalco, J.A., Rowe, J.P., Paquette, L. et al. Detecting and Addressing Frustration in a Serious Game for Military Training. Int J Artif Intell Educ 28, 152–193 (2018). https://doi.org/10.1007/s40593-017-0152-1","Tutoring systems that are sensitive to affect show considerable promise for enhancing student learning experiences. Creating successful affective responses requires considerable effort both to detect student affect and to design appropriate responses to affect. Recent work has suggested that affect detection is more effective when both physical sensors and interaction logs are used, and that context-sensitive design of affective feedback is necessary to enhance engagement and improve learning. In this paper, we provide a comprehensive report on a multi-part study that integrates detection, validation, and intervention into a unified approach. This paper examines the creation of both sensor-based and interaction-based detectors of student affect, producing successful detectors of student affect. In addition, it reports results from an investigation of motivational feedback messages designed to address student frustration, and investigates whether linking these interventions to detectors improves outcomes. Our results are mixed, finding that self-efficacy enhancing interventions based on interaction-based affect detectors enhance outcomes in one of two experiments investigating affective interventions. This work is conducted in the context of the GIFT framework for intelligent tutoring, and the TC3Sim game-based simulation that provides training for first responder skills."
"Teaching and Learning in the Pleistocene: A Biocultural Account of Human Pedagogy and Its Implications for AIED","International Journal of Artificial Intelligence in Education","volume28","439","469","2018","Morrison, D.M., Miller, K.B. Teaching and Learning in the Pleistocene: A Biocultural Account of Human Pedagogy and Its Implications for AIED. Int J Artif Intell Educ 28, 439–469 (2018). https://doi.org/10.1007/s40593-017-0153-0",""
"Modeling Expert Behavior in Support of an Adaptive Psychomotor Training Environment: a Marksmanship Use Case","International Journal of Artificial Intelligence in Education","volume28","194","224","2018","Goldberg, B., Amburn, C., Ragusa, C. et al. Modeling Expert Behavior in Support of an Adaptive Psychomotor Training Environment: a Marksmanship Use Case. Int J Artif Intell Educ 28, 194–224 (2018). https://doi.org/10.1007/s40593-017-0155-y","The U.S. Army is interested in extending the application of intelligent tutoring systems (ITS) beyond cognitive problem spaces and into psychomotor skill domains. In this paper, we present a methodology and validation procedure for creating expert model representations in the domain of rifle marksmanship. GIFT (Generalized Intelligent Framework for Tutoring) was used as the architecture to guide development efforts and was paired with an Army marksmanship simulator that collects behavioral information through sensor technologies. The models were based on expert data from eight members of the U.S. Army Marksmanship Unit’s Service Rifle Team. The goal is to establish validated models that serve as artificial intelligence assessment criteria for driving a self-regulated training environment. We review the techniques applied to the data for model construction, the trends found in the data that are generalized across each expert informed through cross-fold validation practices, and discuss how the models will be used for driving real-time assessment. Results support the utility of generalized expert models across the fundamental components of rifle marksmanship as outlined in U.S. Army doctrine."
"How Do English Language Learners Interact with Different Content Types in MOOC Videos?","International Journal of Artificial Intelligence in Education","volume28","508","527","2018","Uchidiuno, J., Koedinger, K., Hammer, J. et al. How Do English Language Learners Interact with Different Content Types in MOOC Videos?. Int J Artif Intell Educ 28, 508–527 (2018). https://doi.org/10.1007/s40593-017-0156-x","English Language Learners (ELLs) are a substantial portion of the students who enroll in MOOCs. In order to fulfill the promise of MOOCs – i.e., making higher education accessible to everyone with an internet connection – appropriate interventions should be offered to students who struggle with the language of course content. Through the analysis of clickstream log data gathered from two MOOC courses deployed on Coursera, Introduction to Psychology and Statistical Thermodynamics, we show that compared to native English speakers, ELL students have distinct behavioral patterns in how they engage with MOOC content including increased interaction with content that contains text, increased seeking away from content without visual support, and decreased video play rates. These patterns are expressed differently in response to different types of course content and domains. Our findings not only suggest more fine-grained methods for automatically identifying students who need language interventions, but also have further implications for the design of language support interventions and MOOC videos."
"Authoring Tools for Designing Intelligent Tutoring Systems: a Systematic Review of the Literature","International Journal of Artificial Intelligence in Education","volume28","336","384","2018","Dermeval, D., Paiva, R., Bittencourt, I. et al. Authoring Tools for Designing Intelligent Tutoring Systems: a Systematic Review of the Literature. Int J Artif Intell Educ 28, 336–384 (2018). https://doi.org/10.1007/s40593-017-0157-9","Authoring tools have been broadly used to design Intelligent Tutoring Systems (ITS). However, ITS community still lacks a current understanding of how authoring tools are used by non-programmer authors to design ITS. Hence, the objective of this work is to review how authoring tools have been supporting ITS design for non-programmer authors. In order to meet our goal, we conduct a Systematic Literature Review (SLR) to identify the primary studies on the use of ITS authoring tools, following a pre-defined review protocol. Among the 4622 papers retrieved from seven digital libraries published from 2009 to June 2016, 33 papers are finally included after applying our exclusion and inclusion criteria. We then identify the main ITS components authored, the ITS types designed, the features used to facilitate the authoring process, the technologies used to develop authoring tools and the time at which authoring occurs. We also look for evidence of the benefits of ITS authoring tools. In summary, the main findings of this work are: (1) there is empirical evidence of the benefits (i.e., mainly in terms of effectiveness, efficiency, quality of authored artifacts, and usability) of using ITS authoring tools for non-programmer authors, specially to aid authoring of learning content and to support authoring of model-tracing/cognitive and example-tracing tutors; 2) domain and pedagogical models have been much more targeted by authoring tools; (3) several ITS types have been authored, with an emphasis on model-tracing/cognitive and example-tracing tutors; (4) besides providing features for authoring all four ITS components, current authoring tools are also presenting general features (e.g., view learners’ statistics and reuse tutor design) to create broader authoring tools; (5) a great diversity of technologies, which include AI techniques, software solutions and distributed technologies, are used to develop ITS authoring tools; and (6) authoring tools have been mainly targeting ITS design before students’ instruction, but works are also addressing authoring during and/or post-instruction relying both on human and artificial intelligence. We conclude this work by showing several promising research opportunities that are quite important and interesting but underexplored in current research and practice."
"Preface: Special Issue on Multidisciplinary Approaches to AI and Education for Reading and Writing","International Journal of Artificial Intelligence in Education","volume27","665","670","2017","Passonneau, R.J., McNamara, D., Muresan, S. et al. Preface: Special Issue on Multidisciplinary Approaches to AI and Education for Reading and Writing. Int J Artif Intell Educ 27, 665–670 (2017). https://doi.org/10.1007/s40593-017-0158-8",""
"Going Global: Understanding English Language Learners’ Student Motivation in English-Language MOOCs","International Journal of Artificial Intelligence in Education","volume28","528","552","2018","Uchidiuno, J.O., Ogan, A., Yarzebinski, E. et al. Going Global: Understanding English Language Learners’ Student Motivation in English-Language MOOCs. Int J Artif Intell Educ 28, 528–552 (2018). https://doi.org/10.1007/s40593-017-0159-7","Massive Open Online Courses (MOOCs) offer high quality, free courses to anyone with an Internet connection. However, these courses may be relatively inaccessible to the large global population of students who are English Language Learners (ELLs). Current efforts to understand student motivation in MOOCs do not take into account the specific needs of ELL students. Through interviews with 12 ELL online students, and a survey with 20,084 ELL respondents, we investigate ELL students’ motivations for taking online courses. We show that ELL students’ motivations are highly socialized strategies for achieving long-term goals of economic, social, and geographic mobility. Although research studies show that ELLs interact sparingly with other students in MOOCs, we present evidence that they have unmet needs for interaction, and discuss how student interaction systems in MOOCs can better address these needs. Finally, we show evidence that ELLs deliberately use English MOOCs to improve their language skills, even when the content is not language-related. This implies that meeting ELL students’ needs and access to MOOCs involves translating MOOCs to their local languages, but also providing language support in English-language MOOCs."
"A Multimodal Analysis of Making","International Journal of Artificial Intelligence in Education","volume28","385","419","2018","Worsley, M., Blikstein, P. A Multimodal Analysis of Making. Int J Artif Intell Educ 28, 385–419 (2018). https://doi.org/10.1007/s40593-017-0160-1","This paper presents three multimodal learning analytic approaches from a hands-on learning activity. We use video, audio, gesture and bio-physiology data from a two-condition study (N = 20), to identify correlations between the multimodal data, experimental condition, and two learning outcomes: design quality and learning. The three approaches incorporate: 1) human-annotated coding of video data, 2) automated coding of gesture, audio and bio-physiological data and, 3) concatenated human-annotated and automatically annotated data. Within each analysis we employ the same machine learning and sequence mining techniques. Ultimately we find that each approach provides different affordances depending on the similarity metric and the dependent variable. For example, the analysis based on human-annotated data found strong correlations among multimodal behaviors, experimental condition, success and learning, when we relaxed constraints on temporal similarity. The second approach performed well when comparing students’ multimodal behaviors as a time series, but was less effective using the temporally relaxed similarity metric. The take-away is that there are several strategies for doing multimodal learning analytics, and that many of these approaches can provide a meaningful glimpse into a complex data set, glimpses that may be difficult to identify using traditional approaches."
"The Civic Mission of MOOCs: Engagement across Political Differences in Online Forums","International Journal of Artificial Intelligence in Education","volume28","553","589","2018","Yeomans, M., Stewart, B.M., Mavon, K. et al. The Civic Mission of MOOCs: Engagement across Political Differences in Online Forums. Int J Artif Intell Educ 28, 553–589 (2018). https://doi.org/10.1007/s40593-017-0161-0","Massive open online courses (MOOCs) attract diverse student bodies, and course forums could potentially be an opportunity for students with different political beliefs to engage with one another. We test whether this engagement actually takes place in two politically-themed MOOCs, on education policy and American government. We collect measures of students’ political ideology, and then observe student behavior in the course discussion boards. Contrary to the common expectation that online spaces often become echo chambers or ideological silos, we find that students in these two political courses hold diverse political beliefs, participate equitably in forum discussions, directly engage (through replies and upvotes) with students holding opposing beliefs, and converge on a shared language rather than talking past one another. Research that focuses on the civic mission of MOOCs helps ensure that open online learning engages the same breadth of purposes that higher education aspires to serve."
"Scaling Academic Writing Instruction: Evaluation of a Scaffolding Tool (Thesis Writer)","International Journal of Artificial Intelligence in Education","volume28","590","615","2018","Rapp, C., Kauf, P. Scaling Academic Writing Instruction: Evaluation of a Scaffolding Tool (Thesis Writer). Int J Artif Intell Educ 28, 590–615 (2018). https://doi.org/10.1007/s40593-017-0162-z","No thesis - no graduation. Academic writing poses manifold challenges to students, instructors and institutions alike. High labor costs, increasing student numbers, and the Bologna Process (which has reduced the period after which undergraduates in Europe submit their first thesis and thus the time available to focus on writing skills) all pose a threat to students’ academic writing abilities. This situation gave rise to the practical goal of this study: to determine if, and to what extent, academic writing and its instruction can be scaled (i.e., designed more efficiently) using a technological solution, in this case Thesis Writer (TW), a domain-specific, online learning environment for the scaffolding of student academic writing, combined with an online editor optimized for producing academic text. Compared to existing automated essay scoring and writing evaluation tools, TW is not focusing on feedback but on instruction, planning, and genre mastery. While most US-based tools, particularly those also used in secondary education, are targeting on the essay genre, TW is tailored to the needs of theses and research article writing (IMRD scheme). This mixed-methods paper reports data of a test run with a first-year course of 102 business administration students. A technology adoption model served as a frame of reference for the research design. From a student’s perspective, problems posed by the task of writing a research proposal as well as the use, usability, and usefulness of TW were studied through an online survey and focus groups (explanatory sequential design). Results seen were positive to highly positive – TW is being used, and has been deemed supportive by students. In particular, it supports the scaling of writing instruction in group assignment settings."
"Automated Test Assembly for Handling Learner Cold-Start in Large-Scale Assessments","International Journal of Artificial Intelligence in Education","volume28","616","631","2018","Vie, J., Popineau, F., Bruillard, É. et al. Automated Test Assembly for Handling Learner Cold-Start in Large-Scale Assessments. Int J Artif Intell Educ 28, 616–631 (2018). https://doi.org/10.1007/s40593-017-0163-y","In large-scale assessments such as the ones encountered in MOOCs, a lot of usage data is available because of the number of learners involved. Newcomers, that just arrive on a MOOC, have various backgrounds in terms of knowledge, but the platform hardly knows anything about them. Therefore, it is crucial to elicit their knowledge fast, in order to personalize their learning experience. Such a problem has been called learner cold-start. We present in this article an algorithm for sampling a group of initial, diverse questions for a newcomer, based on a method recently used in machine learning: determinantal point processes. We show, using real data, that our method outperforms existing techniques such as uncertainty sampling, and can provide useful feedback to the learner over their strong and weak points."
"Ontology-Based Generation of Medical, Multi-term MCQs","International Journal of Artificial Intelligence in Education","volume29","145","188","2019","Leo, J., Kurdi, G., Matentzoglu, N. et al. Ontology-Based Generation of Medical, Multi-term MCQs. Int J Artif Intell Educ 29, 145–188 (2019). https://doi.org/10.1007/s40593-018-00172-w","Designing good multiple choice questions (MCQs) for education and assessment is time consuming and error-prone. An abundance of structured and semi-structured data has led to the development of automatic MCQ generation methods. Recently, ontologies have emerged as powerful tools to enable the automatic generation of MCQs. However, current question generation approaches focus on knowledge recall questions. In addition, questions that have so far been generated are, compared to manually created ones, simple and cover only a small subset of the required question complexity space in the education and assessment domain. In this paper, we focus on addressing the limitations of previous approaches by generating questions with complex stems that are suitable for scenarios beyond mere knowledge recall. We present a novel ontology-based approach that exploits classes and existential restrictions to generate case-based questions. Our contribution lies in: (1) the specification of procedure for generating case-based questions which involve (a) assembling complex stems, (b) selecting suitable options, and (c) providing explanations for option correctness/incorrectness, (2) an implementation of the procedure using a medical ontology and (3) and evaluation of our generation technique to test question quality and their suitability in practise. We implement our approach as an application for a medical education scenario on top of a large knowledge base in the medical domain. We generate more than 3 million questions for four physician specialities and evaluate our approach in a user study with 15 medical experts. We find that using a stratified random sample of 435 questions out of which 316 were rated by two experts, 129 (30%) are considered appropriate to be used in exams by both experts and a further 216 (50%) by at least one expert."
"Inferring Students’ Personality from Their Communication Behavior in Web-based Learning Systems","International Journal of Artificial Intelligence in Education","volume29","189","216","2019","Wu, W., Chen, L., Yang, Q. et al. Inferring Students’ Personality from Their Communication Behavior in Web-based Learning Systems. Int J Artif Intell Educ 29, 189–216 (2019). https://doi.org/10.1007/s40593-018-00173-9","Communication tools have been popular in web-based learning systems because of their ability to promote the interaction and potentially alleviate the high dropout issue. In recent years, with the increased awareness among researchers about the individual difference of the students, more and more personalized learning supports have been developed. Although personality has been considered as a valuable personal factor being incorporated into the provision of personalized learning, existing studies mainly acquire students’ personality via questionnaires, which unavoidably demands user efforts. In this paper, we are motivated to derive students’ Big-Five personality from their communication behavior in web-based learning systems. Concretely, we first identify a set of features that are significantly influenced by students’ personality, which not only include their communication activities carried out in both synchronous and asynchronous web-based learning environment, but also their linguistic content in conversational texts. We then develop inference model to unify these features for determining students’ five personality traits, and find that students’ usage of different communication tools can be effective in predicting their Big-Five personality."
"Metacognitive Overload!: Positive and Negative Effects of Metacognitive Prompts in an Intelligent Tutoring System","International Journal of Artificial Intelligence in Education","volume28","420","438","2018","McCarthy, K.S., Likens, A.D., Johnson, A.M. et al. Metacognitive Overload!: Positive and Negative Effects of Metacognitive Prompts in an Intelligent Tutoring System. Int J Artif Intell Educ 28, 420–438 (2018). https://doi.org/10.1007/s40593-018-0164-5","Research suggests that promoting metacognitive awareness can increase performance in, and learning from, intelligent tutoring systems (ITSs). The current work examines the effects of two metacognitive prompts within iSTART, a reading comprehension strategy ITS in which students practice writing quality self-explanations. In addition to comparing iSTART practice to a no-training control, those in the iSTART condition (n<U+2009>=<U+2009>116) were randomly assigned to a 2 (performance threshold: off, on)<U+2009>×<U+2009>2(self-assessment: off, on) design. The performance threshold notified students when their average self-explanation score was below an experimenter-set threshold and the self-assessment prompted students to estimate their self-explanation score on the current trial. Students who practiced with iSTART had higher posttest self-explanation scores and inference comprehension scores on a transfer test than students in the no training control, replicating previous benefits for iSTART. However, there were no effects of either metacognitive prompt on these learning outcomes. In-system self-explanation scores indicated that the metacognitive prompts were detrimental to performance relative to standard iSTART practice. This study did not find benefits of metacognitive prompts in enhancing performance during practice or after the completion of training. Such findings support the idea that improving reading comprehension strategies comes from deliberate practice with actionable feedback rather than explicit metacognitive supports."
"How Does Prior Knowledge Influence Eye Fixations and Sequences of Cognitive and Metacognitive SRL Processes during Learning with an Intelligent Tutoring System?","International Journal of Artificial Intelligence in Education","volume29","1","28","2019","Taub, M., Azevedo, R. How Does Prior Knowledge Influence Eye Fixations and Sequences of Cognitive and Metacognitive SRL Processes during Learning with an Intelligent Tutoring System?. Int J Artif Intell Educ 29, 1–28 (2019). https://doi.org/10.1007/s40593-018-0165-4","The goal of this study was to use eye-tracking and log-file data to investigate the impact of prior knowledge on college students’ (N<U+2009>=<U+2009>194, with a subset of n<U+2009>=<U+2009>30 for eye tracking and sequence mining analyses) fixations on (i.e., looking at) self-regulated learning-related areas of interest (i.e., specific locations on the interface) and on the sequences of engaging in cognitive and metacognitive self-regulated learning processes during learning with MetaTutor, an Intelligent Tutoring System that teaches students about the human circulatory system. Results revealed that there were no significant differences in fixations on single areas of interest by the prior knowledge group students were assigned to; however there were significant differences in fixations on pairs of areas of interest, as evidenced by eye-tracking data. Furthermore, there were significant differences in sequential patterns of engaging in cognitive and metacognitive self-regulated learning processes by students’ prior knowledge group, as evidenced from log-file data. Specifically, students with high prior knowledge engaged in processes containing cognitive strategies and metacognitive strategies whereas students with low prior knowledge did not. These results have implications for designing adaptive intelligent tutoring systems that provide individualized scaffolding and feedback based on individual differences, such as levels of prior knowledge."
"Effects of Voice-Based Synthetic Assistant on Performance of Emergency Care Provider in Training","International Journal of Artificial Intelligence in Education","volume29","122","143","2019","Damacharla, P., Dhakal, P., Stumbo, S. et al. Effects of Voice-Based Synthetic Assistant on Performance of Emergency Care Provider in Training. Int J Artif Intell Educ 29, 122–143 (2019). https://doi.org/10.1007/s40593-018-0166-3","As part of a perennial project, our team is actively engaged in developing new synthetic assistant (SA) technologies to assist in training combat medics and medical first responders. It is critical that medical first responders are well trained to deal with emergencies more effectively. This would require real-time monitoring and feedback for each trainee. Therefore, we introduced a voice-based SA to augment the training process of medical first responders and enhance their performance in the field. The potential benefits of SAs include a reduction in training costs and enhanced monitoring mechanisms. Despite the increased usage of voice-based personal assistants (PAs) in day-to-day life, the associated effects are commonly neglected for a study of human factors. Therefore, this paper focuses on performance analysis of the developed voice-based SA in emergency care provider training for a selected emergency treatment scenario. The research discussed in this paper follows design science in developing proposed technology; at length, we discussed architecture and development and presented working results of voice-based SA. The empirical testing was conducted on two groups as user studies using statistical analysis tools, one trained with conventional methods and the other with the help of SA. The statistical results demonstrated the amplification in training efficacy and performance of medical responders powered by SA. Furthermore, the paper also discusses the accuracy and time of task execution (t) and concludes with the guidelines for resolving the identified problems."
"Instructing a Teachable Agent with Low or High Self-Efficacy – Does Similarity Attract?","International Journal of Artificial Intelligence in Education","volume29","89","121","2019","Tärning, B., Silvervarg, A., Gulz, A. et al. Instructing a Teachable Agent with Low or High Self-Efficacy – Does Similarity Attract?. Int J Artif Intell Educ 29, 89–121 (2019). https://doi.org/10.1007/s40593-018-0167-2","This study examines the effects of teachable agents’ expressed self-efficacy on students. A total of 166 students, 10- to 11-years-old, used a teachable agent-based math game focusing on the base-ten number system. By means of data logging and questionnaires, the study compared the effects of high vs. low agent self-efficacy on the students’ in-game performance, their own math self-efficacy, and their attitude towards their agent. The study further explored the effects of matching vs. mismatching between student and agent with respect to self-efficacy. Overall, students who interacted with an agent with low self-efficacy performed better than students interacting with an agent with high self-efficacy. This was especially apparent for students who had reported low self-efficacy themselves, who performed on par with students with high self-efficacy when interacting with a digital tutee with low self-efficacy. Furthermore, students with low self-efficacy significantly increased their self-efficacy in the matched condition, i.e. when instructing a teachable agent with low self-efficacy. They also increased their self-efficacy when instructing a teachable agent with high self-efficacy, but to a smaller extent and not significantly. For students with high self-efficacy, a potential corresponding effect on a self-efficacy change due to matching may be hidden behind a ceiling effect. As a preliminary conclusion, on the basis of the results of this study, we propose that teachable agents should preferably be designed to have low self-efficacy."
"Personalizing Algebra to Students’ Individual Interests in an Intelligent Tutoring System: Moderators of Impact","International Journal of Artificial Intelligence in Education","volume29","58","88","2019","Walkington, C., Bernacki, M.L. Personalizing Algebra to Students’ Individual Interests in an Intelligent Tutoring System: Moderators of Impact. Int J Artif Intell Educ 29, 58–88 (2019). https://doi.org/10.1007/s40593-018-0168-1","Students experience mathematics in their day-to-day lives as they pursue their individual interests in areas like sports or video games. The present study explores how connecting to students’ individual interests can be used to personalize learning using an Intelligent Tutoring System (ITS) for algebra. We examine the idea that the effects of personalization may be moderated by students’ depth of quantitative engagement with their out-of-school interests. We also examine whether math problems designed to draw upon students’ knowledge of their individual interests at a deep level (i.e., actual quantitative experiences) or surface level (i.e., superficial changes to problem topic) have differential effects. Results suggest that connecting math instruction to students’ out-of-school interests can be beneficial for learning in an ITS and reduces gaming the system. However, benefits may only be realized when students’ degree of quantitative engagement with their out-of-school interests matches the depth at which the personalized problems are written. Students whose quantitative engagement with their interests is minimal may benefit most when problems draw upon superficial aspects of their interest areas. Students who report significant quantitative engagement with their interests may benefit most when individual interests are deeply incorporated into the quantitative structure of math problems. We also find that problems with deeper personalization may spur positive affective states and ward off negative ones for all students. Findings suggest depth is a critical feature of personalized learning with implications for theory and AI instructional design."
"Learning at Scale","International Journal of Artificial Intelligence in Education","volume28","471","477","2018","Roll, I., Russell, D.M. & Gaševic, D. Learning at Scale. Int J Artif Intell Educ 28, 471–477 (2018). https://doi.org/10.1007/s40593-018-0170-7","Learning at Scale is a fast growing field that affects formal, informal, and workplace education. Highly interdisciplinary, it builds on solid foundations in the learning sciences, computer science, education, and the social sciences. We define learning at scale as the study of the technologies, pedagogies, analyses, and theories of learning and teaching that take place with a large number of learners and a high ratio of learners to facilitators. The scale of these environments often changes the very nature of the interaction and learning experiences. We identify three types of technologies that support scale in education: dedicated content-agnostic platforms, such as MOOCs; dedicated tools, such as Intelligent Tutoring Systems; and repurposed platforms, such as social networks. We further identify five areas that scale affects: learners, research and data, adaptation, space and time, and pedagogy. Introducing the papers in this special issue on the topic, we discuss the characteristics, affordances, and promise of learning at scale."
"Adding Communicative and Affective Strategies to an Embodied Conversational Agent to Enhance Second Language Learners’ Willingness to Communicate","International Journal of Artificial Intelligence in Education","volume29","29","57","2019","Ayedoun, E., Hayashi, Y. & Seta, K. Adding Communicative and Affective Strategies to an Embodied Conversational Agent to Enhance Second Language Learners’ Willingness to Communicate. Int J Artif Intell Educ 29, 29–57 (2019). https://doi.org/10.1007/s40593-018-0171-6","This paper describes an embodied conversational agent enhanced with specific conversational strategies aiming to foster learners’ readiness towards communication in a second language (L2). Willingness to communicate (WTC) in a second language is believed to have a direct and sustained influence on learners’ actual usage frequency of the target language. To help overcome the lack of suitable environments for increasing L2 learners’ WTC, our approach is to build embodied conversational agents that can help learners surmount their apprehension towards communication in L2. Here, we focus on the dialogue management aspects of our approach and propose a model based on a set of communication strategies (CS) and affective backchannels (AB) to foster such agents’ ability to carry on natural and WTC-friendly conversations with learners. We examined learners’ expected WTC after interacting with one of the following versions of the system: an agent featuring both CS and AB; an agent featuring only CS; and an agent featuring only AB. The results suggested that combining CS and AB empowers the conversational agent and leads to higher expected WTC among L2 learners. We also found that even the AB-only version of the system had the potential to enhance WTC to some extent. These findings are evidence of the feasibility of enhancing L2 learners’ engagement towards communication using a computer-based environment coupled with appropriate conversational strategies."
"Automated Analysis of Reflection in Writing: Validating Machine Learning Approaches","International Journal of Artificial Intelligence in Education","volume29","217","257","2019","Ullmann, T.D. Automated Analysis of Reflection in Writing: Validating Machine Learning Approaches. Int J Artif Intell Educ 29, 217–257 (2019). https://doi.org/10.1007/s40593-019-00174-2","Reflective writing is an important educational practice to train reflective thinking. Currently, researchers must manually analyze these writings, limiting practice and research because the analysis is time and resource consuming. This study evaluates whether machine learning can be used to automate this manual analysis. The study investigates eight categories that are often used in models to assess reflective writing, and the evaluation is based on 76 student essays (5080 sentences) that are largely from third- and second-year health, business, and engineering students. To test the automated analysis of reflection in writings, machine learning models were built based on a random sample of 80% of the sentences. These models were then tested on the remaining 20% of the sentences. Overall, the standardized evaluation shows that five out of eight categories can be detected automatically with substantial or almost perfect reliability, while the other three categories can be detected with moderate reliability (Cohen’s <U+03BA> ranges between .53 and .85). The accuracies of the automated analysis were on average 10% lower than the accuracies of the manual analysis. These findings enable reflection analytics that is immediate and scalable."
"Incorporating Features Learned by an Enhanced Deep Knowledge Tracing Model for STEM/Non-STEM Job Prediction","International Journal of Artificial Intelligence in Education","volume29","317","341","2019","Yeung, C., Yeung, D. Incorporating Features Learned by an Enhanced Deep Knowledge Tracing Model for STEM/Non-STEM Job Prediction. Int J Artif Intell Educ 29, 317–341 (2019). https://doi.org/10.1007/s40593-019-00175-1","The 2017 ASSISTments Data Mining competition aims to use data from a longitudinal study for predicting a brand-new outcome of students which had never been studied before by the educational data mining research community. Specifically, it facilitates research in developing predictive models that predict whether the first job of a student out of college belongs to a STEM (the acronym for science, technology, engineering, and mathematics) field. This is based on the student’s learning history on the ASSISTments blended learning platform in the form of extensive clickstream data gathered during the middle school years. To tackle this challenge, we first estimate the expected knowledge state of students with respect to different mathematical skills using a deep knowledge tracing (DKT) model and an enhanced DKT (DKT+) model. We then combine the features corresponding to the DKT/DKT+ expected knowledge state with other features extracted directly from the student profile in the dataset to train several machine learning models for the STEM/non-STEM job prediction. Our experiments show that models trained with the combined features generally perform better than the models trained with the student profile alone. Detailed analysis on the student’s knowledge state reveals that, when compared with non-STEM students, STEM students generally show a higher mastery level and a higher learning gain in mathematics."
"A Data-Based Simulation Study of Reliability for an Adaptive Assessment Based on Knowledge Space Theory","International Journal of Artificial Intelligence in Education","volume29","258","282","2019","Doble, C., Matayoshi, J., Cosyn, E. et al. A Data-Based Simulation Study of Reliability for an Adaptive Assessment Based on Knowledge Space Theory. Int J Artif Intell Educ 29, 258–282 (2019). https://doi.org/10.1007/s40593-019-00176-0","A large-scale simulation study of the assessment effectiveness of a particular instantiation of knowledge space theory is described. In this study, data from more than 700,000 actual assessments in mathematics using the ALEKS (Assessment and LEarning in Knowledge Spaces) software were used to determine response probabilities for the same number of simulated assessments, for the purpose of examining reliability. Several measures of reliability were examined, borrowed from existing psychometric approaches, with an eye toward developing measures for evaluating reliability for adaptive assessments. The results are compared to analogous results for assessments having mathematics content overlapping that of the ALEKS assessment, and some consequences and future directions are discussed."
"A Comparison of the Quality of Data-Driven Programming Hint Generation Algorithms","International Journal of Artificial Intelligence in Education","volume29","368","395","2019","Price, T.W., Dong, Y., Zhi, R. et al. A Comparison of the Quality of Data-Driven Programming Hint Generation Algorithms. Int J Artif Intell Educ 29, 368–395 (2019). https://doi.org/10.1007/s40593-019-00177-z","In the domain of programming, a growing number of algorithms automatically generate data-driven, next-step hints that suggest how students should edit their code to resolve errors and make progress. While these hints have the potential to improve learning if done well, few evaluations have directly assessed or compared the quality of different hint generation approaches. In this work, we present the QualityScore procedure, a novel method for automatically evaluating and comparing the quality of next-step programming hints using expert ratings. We first demonstrate that the automated QualityScore ratings agree with experts’ manual ratings. We then use the QualityScore procedure to compare the quality of six data-driven, next-step hint generation algorithms using two distinct programming datasets in two different programming languages. Our results show that there are large and significant differences between the quality of the six algorithms and that these differences are relatively consistent across datasets and problems. We also identify situations where the six algorithms struggle to produce high-quality hints, and we suggest ways that future work might address these challenges. We make our methods and data publicly available and encourage researchers to use the QualityScore procedure to evaluate additional algorithms and benchmark them against our results."
"Problematizing Helps! A Classroom Study of Computer-Based Guidance for Invention Activities","International Journal of Artificial Intelligence in Education","volume29","283","316","2019","Chase, C.C., Connolly, H., Lamnina, M. et al. Problematizing Helps! A Classroom Study of Computer-Based Guidance for Invention Activities. Int J Artif Intell Educ 29, 283–316 (2019). https://doi.org/10.1007/s40593-019-00178-y","A successful instructional method is to engage learners with exploratory problem-solving before providing explanations of the canonical solutions and foundational concepts. A key question is whether and what type of guidance will lead learners to explore more productively and how this guidance will affect subsequent learning and transfer. We investigate this question through the design and study of the Invention Coach, an adaptive, computer-based learning environment that problematizes students’ understanding as they invent fundamental physics equations. Problematizing guidance (Reiser Journal of the Learning Sciences, 13(3), 273–304, 2004), which encourages learners to grapple with domain complexity, is well-suited to the goals of Invention. However, there are few examples of technology-based learning environments that were explicitly designed to problematize and scant research on their efficacy. In an experimental study, 199 middle schoolers worked with either motivational, task<U+2009>+<U+2009>motivational, or problematizing<U+2009>+<U+2009>task<U+2009>+<U+2009>motivational guidance versions of the Coach while inventing. Students who engaged with the problematizing Coach were better able to transfer their knowledge to novel domains in the short term, and their transfer gains were comparable to those provoked by human tutors. While students in the problematizing condition were less likely to invent the correct solutions, they engaged in more targeted and efficient exploration of the solution space and were less likely to report experiences of difficulty. Findings suggest that problematizing guidance has the potential to effectively support exploratory problem-solving, when the goal is to facilitate productive exploration and transfer from subsequent instruction. The work also has implications for the design of problematizing guidance."
"Investigating the Effect of Agency on Learning from Worked Examples, Erroneous Examples and Problem Solving","International Journal of Artificial Intelligence in Education","volume29","396","424","2019","Chen, X., Mitrovic, A. & Mathews, M. Investigating the Effect of Agency on Learning from Worked Examples, Erroneous Examples and Problem Solving. Int J Artif Intell Educ 29, 396–424 (2019). https://doi.org/10.1007/s40593-019-00179-x","Agency refers to the level of control the student has over learning. Most studies on agency in computer-based learning environments have been conducted in the context of educational games and multimedia learning, while there is little research done in the context of learning with Intelligent Tutoring Systems (ITSs). We conducted a study in the context of SQL-Tutor, an ITS that teaches database querying, with students solving a fixed set of ten problems. Before each problem, students worked on a preparatory task, which could be presented as a worked example, erroneous example, or another isomorphic problem. There were two conditions in the study. In the High-Agency condition, students could select the type of preparatory task freely or skip it altogether. In the Low-Agency condition, an adaptive strategy selected preparatory tasks for students on the basis of their performance. The participants were classified as High Prior Knowledge (HPK) or Low Prior Knowledge (LPK), based on their scores on the pre-test. Due to the timing of the study, we had 40 participants who completed all elements of the study. The participants in both Low- and High-Agency conditions improved significantly from the pre- to post-test, and there was no difference between the LPK and HPK students on post-test scores. Therefore, we have not found an effect of agency on learning. The Low Agency condition was beneficial for both HPK and LPK students, while in the High Agency condition there was significant improvement between the pre- and post-test only for the LPK students. In the High-Agency group, the HPK students selected more challenging learning activities, but did not outperform LPK students on the post-test scores. The limitation of our study is the small sample size."
"Predicting the Difficulty of Exercise Items for Dynamic Difficulty Adaptation in Adaptive Language Tutoring","International Journal of Artificial Intelligence in Education","volume29","342","367","2019","Pandarova, I., Schmidt, T., Hartig, J. et al. Predicting the Difficulty of Exercise Items for Dynamic Difficulty Adaptation in Adaptive Language Tutoring. Int J Artif Intell Educ 29, 342–367 (2019). https://doi.org/10.1007/s40593-019-00180-4","Advances in computer technology and artificial intelligence create opportunities for developing adaptive language learning technologies which are sensitive to individual learner characteristics. This paper focuses on one form of adaptivity in which the difficulty of learning content is dynamically adjusted to the learner’s evolving language ability. A pilot study is presented which aims to advance the (semi-)automatic difficulty scoring of grammar exercise items to be used in dynamic difficulty adaptation in an intelligent language tutoring system for practicing English tenses. In it, methods from item response theory and machine learning are combined with linguistic item analysis in order to calibrate the difficulty of an initial exercise pool of cued gap-filling items (CGFIs) and isolate CGFI features predictive of item difficulty. Multiple item features at the gap, context and CGFI levels are tested and relevant predictors are identified at all three levels. Our pilot regression models reach encouraging prediction accuracy levels which could, pending additional validation, enable the dynamic selection of newly generated items ranging from moderately easy to moderately difficult. The paper highlights further applications of the proposed methodology in the area of adapting language tutoring, item design and second language acquisition, and sketches out issues for future research."
"Using Lexical Properties of Handwritten Equations to Estimate the Correctness of Students’ Solutions to Engineering Problems","International Journal of Artificial Intelligence in Education","volume29","459","483","2019","Stahovich, T.F., Lin, H. & Gyllen, J. Using Lexical Properties of Handwritten Equations to Estimate the Correctness of Students’ Solutions to Engineering Problems. Int J Artif Intell Educ 29, 459–483 (2019). https://doi.org/10.1007/s40593-019-00181-3","We present a technique that examines handwritten equations from a student’s solution to an engineering problem and from this estimates the correctness of the work. More specifically, we demonstrate that lexical properties of the equations correlate with the grade a human grader would assign. We characterize these properties with a set of features that include the number of occurrences of various classes of symbols and binary and tripartite sequences of them. Support vector machine (SVM) regression models trained with these features achieved a correlation of r = .433 (p< .001) on a combined set of six exam problems. Prior work suggests that the number of long pauses in the writing that occur as a student solves a problem correlates with correctness. We found that combining this pause feature with our lexical features produced more accurate predictions than using either type of feature alone. SVM regression models trained using an optimized subset of three lexical features and the pause feature achieved an average correlation with grade across the six problems of r = .503 (p< .001). These techniques are an important step toward creating systems that can automatically assess handwritten coursework."
"Data-Driven Development and Evaluation of Enskill English","International Journal of Artificial Intelligence in Education","volume29","425","457","2019","Johnson, W.L. Data-Driven Development and Evaluation of Enskill English. Int J Artif Intell Educ 29, 425–457 (2019). https://doi.org/10.1007/s40593-019-00182-2","Cloud computing offers developers of learning environments access to unprecedented amounts of learner data. This makes possible data-driven development (D3) of learning environments. In the D3 approach the learning environment is a data collection tool as well a learning tool. It continually collects data from interactions with learners, which is used in ongoing evaluation and iterative development. Iterative development cycles become very rapid, limited by the time required to analyze data and deploy system updates. D3 is particularly relevant to fielded AIED systems that operate in uncontrolled conditions, where learners may behave in unexpected ways. This article presents two snapshot case studies in the data-driven development of Enskill® English, a system for learning to speak English as a foreign language. In the first trial at the University of Novi Sad in Serbia two versions of Enskill English’s dialogue system were tested simultaneously: the released version and a new version incorporating statistical natural language processing technology. A new version was released and data were collected from a second snapshot evaluation at the University of Split, Croatia. Data from learners in Latin America and Europe were analyzed for comparison. The evaluations provided preliminary evidence that Enskill English is helpful for learning spoken English skills, and leading indicators that learner performance improves through practice with Enskill English. They suggest that Enskill English can be extended to meet the needs of more advanced learners who wish to use English in a professional context. Broader recommendations for data-driven development of intelligent learning environments are presented."
"Are MOOC Learning Analytics Results Trustworthy? With Fake Learners, They Might Not Be!","International Journal of Artificial Intelligence in Education","volume29","484","506","2019","Alexandron, G., Yoo, L.Y., Ruipérez-Valiente, J.A. et al. Are MOOC Learning Analytics Results Trustworthy? With Fake Learners, They Might Not Be!. Int J Artif Intell Educ 29, 484–506 (2019). https://doi.org/10.1007/s40593-019-00183-1","The rich data that Massive Open Online Courses (MOOCs) platforms collect on the behavior of millions of users provide a unique opportunity to study human learning and to develop data-driven methods that can address the needs of individual learners. This type of research falls into the emerging field of learning analytics. However, learning analytics research tends to ignore the issue of the reliability of results that are based on MOOCs data, which is typically noisy and generated by a largely anonymous crowd of learners. This paper provides evidence that learning analytics in MOOCs can be significantly biased by users who abuse the anonymity and open-nature of MOOCs, for example by setting up multiple accounts, due to their amount and aberrant behavior. We identify these users, denoted fake learners, using dedicated algorithms. The methodology for measuring the bias caused by fake learners’ activity combines the ideas of Replication Research and Sensitivity Analysis. We replicate two highly-cited learning analytics studies with and without fake learners data, and compare the results. While in one study, the results were relatively stable against fake learners, in the other, removing the fake learners’ data significantly changed the results. These findings raise concerns regarding the reliability of learning analytics in MOOCs, and highlight the need to develop more robust, generalizable and verifiable research methods."
"Evaluation of Parsons Problems with Menu-Based Self-Explanation Prompts in a Mobile Python Tutor","International Journal of Artificial Intelligence in Education","volume29","507","535","2019","Fabic, G.V.F., Mitrovic, A. & Neshatian, K. Evaluation of Parsons Problems with Menu-Based Self-Explanation Prompts in a Mobile Python Tutor. Int J Artif Intell Educ 29, 507–535 (2019). https://doi.org/10.1007/s40593-019-00184-0","The overarching goal of our project is to design effective learning activities for PyKinetic, a smartphone Python tutor. In this paper, we present a study using a variant of Parsons problems we designed for PyKinetic. Parsons problems contain randomized code which needs to be re-ordered to produce the desired effect. In our variant of Parsons problems, students were asked to complete the missing part(s) of some lines of code (LOCs), and rearrange the LOCs to match the problem description. In addition, we added menu-based Self-Explanation (SE) prompts. Students were asked to self-explain concepts related to incomplete LOCs they solved. Our hypotheses were: (H1) PyKinetic would be successful in supporting learning; (H2) menu-based SE prompts would result in further learning benefits; (H3) students with low prior knowledge (LP) would learn more from our Parsons problems in comparison to those with high prior knowledge (HP). We found that the participants’ scores on the post-test improved, thus showing evidence of learning in PyKinetic. The experimental group participants, who had SE prompts, showed improved learning in comparison to the control group. Further analyses revealed that LP students improved more than HP students and the improvement is even more pronounced for LP learners who self-explained. The contributions of our work are a) pedagogically-guided design of Parsons problems with SE prompts used on smartphones, b) showing that our Parsons problems are effective in supporting learning and c) our Parsons problems with SE prompts are especially effective for students with low prior knowledge."
"Determination of Professional Competencies Using an Alignment Algorithm of Academic Profiles and Job Advertisements, Based on Competence Thesauri and Similarity Measures","International Journal of Artificial Intelligence in Education","volume29","536","567","2019","González-Eras, A., Aguilar, J. Determination of Professional Competencies Using an Alignment Algorithm of Academic Profiles and Job Advertisements, Based on Competence Thesauri and Similarity Measures. Int J Artif Intell Educ 29, 536–567 (2019). https://doi.org/10.1007/s40593-019-00185-z","Describing the competencies required by a profession is essential for aligning online profiles of job seekers and job advertisements. Comparing the competencies described within each context has typically not be done, which has generated a complete disconnect in language between them. This work presents an approach for the alignment of online profiles and job advertisements, according to knowledge and skills, using measures of lexical, syntactic and taxonomic similarity. In addition, we use a ranking that allows the alignment of the profiles to the topics of a thesaurus that define competencies. The results are promising, because the combination of the measures of similarity with the alignment with thesauri of competencies offers robustness to the process of generation of professional competence descriptions. This combination allows dealing with the common problems of synonymy, homonymy, hypernymy/hyponymy and meronymy of the terms in Spanish. This research uses natural language processing to offer a novel approach for assessing the match of the competencies described by the applicants and by the employers, even if they use different terminology. The resulting approach, while developed in Spanish for computer science jobs, can be extended to other languages and domains, such is the case of recruitment, where it will contribute to the creation of better tools that give feedback to job seekers about how to best align their competencies with job opportunities."
"A Systematic Review of Automatic Question Generation for Educational Purposes","International Journal of Artificial Intelligence in Education","volume30","121","204","2020","Kurdi, G., Leo, J., Parsia, B. et al. A Systematic Review of Automatic Question Generation for Educational Purposes. Int J Artif Intell Educ 30, 121–204 (2020). https://doi.org/10.1007/s40593-019-00186-y","While exam-style questions are a fundamental educational tool serving a variety of purposes, manual construction of questions is a complex process that requires training, experience, and resources. This, in turn, hinders and slows down the use of educational activities (e.g. providing practice questions) and new advances (e.g. adaptive testing) that require a large pool of questions. To reduce the expenses associated with manual construction of questions and to satisfy the need for a continuous supply of new questions, automatic question generation (AQG) techniques were introduced. This review extends a previous review on AQG literature that has been published up to late 2014. It includes 93 papers that were between 2015 and early 2019 and tackle the automatic generation of questions for educational purposes. The aims of this review are to: provide an overview of the AQG community and its activities, summarise the current trends and advances in AQG, highlight the changes that the area has undergone in the recent years, and suggest areas for improvement and future opportunities for AQG. Similar to what was found previously, there is little focus in the current literature on generating questions of controlled difficulty, enriching question forms and structures, automating template construction, improving presentation, and generating feedback. Our findings also suggest the need to further improve experimental reporting, harmonise evaluation metrics, and investigate other evaluation methods that are more feasible."
"Where’s the Reward?","International Journal of Artificial Intelligence in Education","volume29","568","620","2019","Doroudi, S., Aleven, V. & Brunskill, E. Where’s the Reward?. Int J Artif Intell Educ 29, 568–620 (2019). https://doi.org/10.1007/s40593-019-00187-x","Since the 1960s, researchers have been trying to optimize the sequencing of instructional activities using the tools of reinforcement learning (RL) and sequential decision making under uncertainty. Many researchers have realized that reinforcement learning provides a natural framework for optimal instructional sequencing given a particular model of student learning, and excitement towards this area of research is as alive now as it was over fifty years ago. But does RL actually help students learn? If so, when and where might we expect it to be most helpful? To help answer these questions, we review the variety of attempts to use RL for instructional sequencing. First, we present a historical narrative of this research area. We identify three waves of research, which gives us a sense of the various communities of researchers that have been interested in this problem and where the field is going. Second, we review all of the empirical research that has compared RL-induced instructional policies to baseline methods of sequencing. We find that over half of the studies found that RL-induced policies significantly outperform baselines. Moreover, we identify five clusters of studies with different characteristics and varying levels of success in using RL to help students learn. We find that reinforcement learning has been most successful in cases where it has been constrained with ideas and theories from cognitive psychology and the learning sciences. However, given that our theories and models are limited, we also find that it has been useful to complement this approach with running more robust offline analyses that do not rely heavily on the assumptions of one particular model. Given that many researchers are turning to deep reinforcement learning and big data to tackle instructional sequencing, we believe keeping these best practices in mind can help guide the way to the reward in using RL for instructional sequencing."
"Impact of an Artificial Intelligence Research Frame on the Perceived Credibility of Educational Research Evidence","International Journal of Artificial Intelligence in Education","volume30","205","235","2020","Cukurova, M., Luckin, R. & Kent, C. Impact of an Artificial Intelligence Research Frame on the Perceived Credibility of Educational Research Evidence. Int J Artif Intell Educ 30, 205–235 (2020). https://doi.org/10.1007/s40593-019-00188-w","Artificial Intelligence (AI) is attracting a great deal of attention and it is important to investigate the public perceptions of AI and their impact on the perceived credibility of research evidence. In the literature, there is evidence that people overweight research evidence when framed in neuroscience findings. In this paper, we present the findings of the first investigation of the impact of an AI frame on the perceived credibility of educational research evidence. In an experimental study, we allocated 605 participants including educators to one of three conditions in which the same educational research evidence was framed within one of: AI, neuroscience, or educational psychology. The results demonstrate that when educational research evidence is framed within AI research, it is considered as less credible in comparison to when it is framed instead within neuroscience or educational psychology. The effect is still evident when the subjects’ familiarity with the framing discipline is controlled for. Furthermore, our results indicate that the general public perceives AI to be: less helpful in assisting us to understand how children learn, lacking in adherence to scientific methods, and to be less prestigious compared to neuroscience and educational psychology. Considering the increased use of AI technologies in Educational settings, we argue that there should be significant attempts to recover the public image of AI being less scientifically robust and less prestigious than educational psychology and neuroscience. We conclude the article suggesting that AI in Education community should attempt to be more actively engaged with key stakeholders of AI and Education to help mitigate such effects."
"Time- and Learner-Dependent Hidden Markov Model for Writing Process Analysis Using Keystroke Log Data","International Journal of Artificial Intelligence in Education","volume30","271","298","2020","Uto, M., Miyazawa, Y., Kato, Y. et al. Time- and Learner-Dependent Hidden Markov Model for Writing Process Analysis Using Keystroke Log Data. Int J Artif Intell Educ 30, 271–298 (2020). https://doi.org/10.1007/s40593-019-00189-9","Teaching writing strategies based on writing processes has attracted wide attention as a method for developing writing skills. The writing process can be generally defined as a sequence of subtasks, such as planning, formulation, and revision. Therefore, instructor feedback is often given based on sequence patterns of those subtasks. For such feedback, instructors need to analyze sequence patterns for all learners, which becomes problematic as the number of learners increases. To resolve this problem, this study proposes a new machine-learning method that estimates sequence patterns from keystroke log data. Specifically, we propose an extension of the Gaussian hidden Markov model that incorporates parameters representing temporal change in a subtask appearance distribution for each learner. Furthermore, we propose a collapsed Gibbs sampling algorithm as the parameter estimation method for the proposed model. We demonstrate effectiveness of the proposed model by applying it to actual keystroke log datasets."
"The Effect of Metacognitive Scaffolding for Learning by Teaching a Teachable Agent","International Journal of Artificial Intelligence in Education","volume30","1","37","2020","Matsuda, N., Weng, W. & Wall, N. The Effect of Metacognitive Scaffolding for Learning by Teaching a Teachable Agent. Int J Artif Intell Educ 30, 1–37 (2020). https://doi.org/10.1007/s40593-019-00190-2","The effect of metacognitive scaffolding for learning by teaching was investigated and compared against learning by being tutored. Three versions of an online learning environment for learning algebra equations were created: (1) APLUS that allows students to interactively teach a synthetic peer with a goal to have the synthetic peer pass the quiz while the system provides students with metacognitive scaffolding on how to teach. (2) AplusTutor that provides cognitive tutoring (i.e., immediate feedback and just-in-time hint) and metacognitive scaffolding on how to learn. And, (3) CogTutor+ that provides traditional cognitive tutoring on mastery learning. Two school studies were conducted with a total of 444 6th through 8th grade students. 208 students completed the study and were included in the analysis. The results show that (i) students’ proficiency in solving equations increased after using our interventions for 4 days, but there was no difference in the effectiveness across three interventions, and (ii) learning by teaching with metacognitive scaffolding facilitated learning equally across various levels of students’ prior competency."
"The Impact of Contextualized Emotions on Self-Regulated Learning and Scientific Reasoning during Learning with a Game-Based Learning Environment","International Journal of Artificial Intelligence in Education","volume30","97","120","2020","Taub, M., Sawyer, R., Lester, J. et al. The Impact of Contextualized Emotions on Self-Regulated Learning and Scientific Reasoning during Learning with a Game-Based Learning Environment. Int J Artif Intell Educ 30, 97–120 (2020). https://doi.org/10.1007/s40593-019-00191-1","The goal of this study was to examine college students’ (n<U+2009>=<U+2009>61) contextualized emotions during in-game actions while playing Crystal Island, a game-based learning environment where students are tasked with solving the mystery of what illness impacted all island inhabitants. We examined emotions during in-game actions: during book reading, after scanning food items for the transmission source, and after submitting a final diagnosis. We dichotomized each activity’s feedback into a positive or negative outcome: a relevant or irrelevant book for solving the mystery, testing food items that generate a positive or negative result, or submitting a correct or incorrect final diagnosis. Results revealed that expressing joy while reading a relevant book and expressing confusion after a positive scan significantly positively predicted overall game score, which we used as a proxy for problem-solving performance. Implications include understanding different levels of emotions students express during learning with all advanced learning technologies."
"Preschoolers’ Understanding of a Teachable Agent-Based Game in Early Mathematics as Reflected in their Gaze Behaviors – an Experimental Study","International Journal of Artificial Intelligence in Education","volume30","38","73","2020","Gulz, A., Londos, L. & Haake, M. Preschoolers’ Understanding of a Teachable Agent-Based Game in Early Mathematics as Reflected in their Gaze Behaviors – an Experimental Study. Int J Artif Intell Educ 30, 38–73 (2020). https://doi.org/10.1007/s40593-020-00193-4","This study investigated how preschool children processed and understood critical information in Magical Garden, a teachable agent-based play-&-learn game targeting early math. We analyzed 36 children’s (ages 4–6 years) real-time behavior during game-use to explore whether children: (i) processed the information meant to support number sense development; (ii) showed an understanding of the teachable agent as an entity with agency. An important methodological goal was to go beyond observable behavior and shed some light on how cognitive processing and understanding in children of such young age can be studied. First, the children played Magical Garden for three weeks to get acquainted with the game. Second, in an experimental part of the study, the children’s gaze behaviors were measured during 5 rounds of interaction with an experimental version of one of the sub-games. The analyses suggest that two of the gaze behaviors were positively correlated with the game performance measure, as hypothesized. Another result was that children looked at the teachable agent significantly more often when the teachable agent had been in charge of gameplay than when it had not. This can be interpreted as an indication that the children had an understanding of their teachable agent as an entity that, like themselves and unlike other dynamic visual elements in the game, made decisions based on own ‘knowledge’. In a broader context, the findings are important in showing the potential gains of combining log data with eye-tracking data for developing and refining AI algorithms for adaptive individual feedback and scaffolding."
"Active Learning is About More Than Hands-On: A Mixed-Reality AI System to Support STEM Education","International Journal of Artificial Intelligence in Education","volume30","74","96","2020","Yannier, N., Hudson, S.E. & Koedinger, K.R. Active Learning is About More Than Hands-On: A Mixed-Reality AI System to Support STEM Education. Int J Artif Intell Educ 30, 74–96 (2020). https://doi.org/10.1007/s40593-020-00194-3","Along with substantial consensus around the power of active learning, comes some lack of precision in what its essential ingredients are. New educational technologies offer vehicles for systematically exploring benefits of alternative techniques for supporting active learning. We introduce a new genre of Intelligent Science Station technology that uses Artificial Intelligence (AI) to support children in learning science by doing science in the real world. We use this system in a randomized controlled trial that investigates whether active learning is best when it is implemented as guided deliberate practice, as constructive “hands-on” activity, or as a combination of both. Automated, reactive guidance is made possible by a specialized AI computer vision algorithm we developed to track what children are doing in the physical environment as they do experiments and discoveries with physical objects. The results support deliberate practice and indicate that having some guided discovery based on effective learning mechanism such as self-explanation, contrasting cases and personalized interactive feedback produces more robust learning compared to exploratory construction alone. Children learning through guided discovery achieve greater understanding of the scientific principles than children learning through hands-on construction alone (4 times more pre-to-post test improvement). Importantly, a combined guided discovery and hands-on construction condition leads to better learning of the very hands-on construction skills that are the sole focus of the hands-on constructive learning condition (>10 times more pre-to-post improvement). These results suggest ways to achieve powerful active learning of science and engineering that go beyond the widespread temptation to equate hands-on activity with effective learning."
"Associating Facial Expressions and Upper-Body Gestures with Learning Tasks for Enhancing Intelligent Tutoring Systems","International Journal of Artificial Intelligence in Education","volume30","236","270","2020","Behera, A., Matthew, P., Keidel, A. et al. Associating Facial Expressions and Upper-Body Gestures with Learning Tasks for Enhancing Intelligent Tutoring Systems. Int J Artif Intell Educ 30, 236–270 (2020). https://doi.org/10.1007/s40593-020-00195-2","Learning involves a substantial amount of cognitive, social and emotional states. Therefore, recognizing and understanding these states in the context of learning is key in designing informed interventions and addressing the needs of the individual student to provide personalized education. In this paper, we explore the automatic detection of learner’s nonverbal behaviors involving hand-over-face gestures, head and eye movements and emotions via facial expressions during learning. The proposed computer vision-based behavior monitoring method uses a low-cost webcam and can easily be integrated with modern tutoring technologies. We investigate these behaviors in-depth over time in a classroom session of 40 minutes involving reading and problem-solving exercises. The exercises in the sessions are divided into three categories: an easy, medium and difficult topic within the context of undergraduate computer science. We found that there is a significant increase in head and eye movements as time progresses, as well as with the increase of difficulty level. We demonstrated that there is a considerable occurrence of hand-over-face gestures (on average 21.35%) during the 40 minutes session and is unexplored in the education domain. We propose a novel deep learning approach for automatic detection of hand-over-face gestures in images with a classification accuracy of 86.87%. There is a prominent increase in hand-over-face gestures when the difficulty level of the given exercise increases. The hand-over-face gestures occur more frequently during problem-solving (easy 23.79%, medium 19.84% and difficult 30.46%) exercises in comparison to reading (easy 16.20%, medium 20.06% and difficult 20.18%)."
"Improving Engagement in Program Construction Examples for Learning Python Programming","International Journal of Artificial Intelligence in Education","volume30","299","336","2020","Hosseini, R., Akhuseyinoglu, K., Brusilovsky, P. et al. Improving Engagement in Program Construction Examples for Learning Python Programming. Int J Artif Intell Educ 30, 299–336 (2020). https://doi.org/10.1007/s40593-020-00197-0","This research is focused on how to support students’ acquisition of program construction skills through worked examples. Although examples have been consistently proven to be valuable for student’s learning, the learning technology for computer science education lacks program construction examples with interactive elements that could engage students. The goal of this work is to investigate the value of the “engaging” features in programming examples. We introduce PCEX, an online tool developed to present program construction examples in an engaging fashion. We also present the results of a controlled study with a between-subject design that was conducted in a large introductory Python programming class to compare PCEX with non-interactive worked examples focused on program construction. The results of our study show the positive impact of interactive program construction examples on student’s engagement, problem-solving performance, and learning."
